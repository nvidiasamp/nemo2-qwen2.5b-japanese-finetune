# NeMo 2.0 Qwen2.5B Japanese Fine-tuning Workshop

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/release/python-380/)
[![NeMo 2.0](https://img.shields.io/badge/NeMo-2.0-green.svg)](https://docs.nvidia.com/nemo-framework/user-guide/latest/)
[![Docker](https://img.shields.io/badge/Docker-supported-blue.svg)](https://www.docker.com/)

## ğŸ¯ Abstract

This workshop repository demonstrates **Parameter-Efficient Fine-Tuning (PEFT)** and **continual learning** techniques for Japanese language adaptation using the **NVIDIA NeMo 2.0 framework**. The project showcases the effective adaptation of the **Qwen2.5-0.5B model** for Japanese language tasks through systematic training optimization and advanced fine-tuning methodologies.

### ğŸ”¥ Key Features
- **Complete Workshop Materials**: From basic setup to advanced Japanese fine-tuning
- **Dual Implementation**: Both framework-based (M1nG) and algorithm-focused (Kosuke) approaches
- **NeMo 2.0 Integration**: Latest framework with optimized configurations
- **Japanese Language Focus**: Specialized preprocessing and training for Japanese NLP
- **Educational Framework**: Step-by-step learning materials for researchers and practitioners

## ğŸš€ Quick Start

### Prerequisites
- **GPU**: NVIDIA GPU with CUDA support (recommended: RTX 3090 or higher, 16GB+ VRAM)
- **Environment**: Docker (recommended) or Conda
- **Framework**: NeMo 2.0 with Python 3.8+

### ğŸ³ Docker Setup (Recommended)
```bash
# Clone the repository
git clone https://github.com/nvidiasamp/nemo2-qwen2.5b-japanese-finetune.git
cd nemo2-qwen2.5b-japanese-finetune

# Start NeMo training environment
bash scripts/training/run_fixed_training.sh
```

### ğŸ”§ Local Environment Setup
```bash
# Create conda environment
conda create -n nemo-japanese python=3.8
conda activate nemo-japanese

# Install dependencies
pip install -r requirements.txt

# Verify installation
python scripts/training/check_environment.py
```

## ğŸ“ Project Structure

```
nemo2-qwen2.5b-japanese-finetune/
â”œâ”€â”€ README.md                          # Main documentation
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ setup.py                          # Package configuration
â”œâ”€â”€ LICENSE                           # MIT License
â”‚
â”œâ”€â”€ src/                              # Source code (simplified structure)
â”‚   â”œâ”€â”€ algorithms/                   # ğŸ”¥ Core algorithms (from Kosuke branch)
â”‚   â”‚   â”œâ”€â”€ 00convert_ja.py          # Japanese text preprocessing
â”‚   â”‚   â”œâ”€â”€ 01_convert_hf_to_nemo.py # HuggingFace to NeMo conversion
â”‚   â”‚   â”œâ”€â”€ 02_qwen25_peft.py        # PEFT fine-tuning implementation  
â”‚   â”‚   â””â”€â”€ 03_qwen25_sft.py         # Standard fine-tuning implementation
â”‚   â””â”€â”€ utils/                        # Unified utility functions
â”‚       â”œâ”€â”€ config_utils.py          # Configuration management
â”‚       â”œâ”€â”€ logging_utils.py         # Logging utilities
â”‚       â”œâ”€â”€ check_gpu_config.py      # GPU validation
â”‚       â”œâ”€â”€ validate_model.py        # Model validation
â”‚       â””â”€â”€ [other utilities]        # Additional helper functions
â”‚
â”œâ”€â”€ scripts/                          # Execution scripts
â”‚   â”œâ”€â”€ training/                     # Training pipeline
â”‚   â”‚   â”œâ”€â”€ nemo_official_fixed_final.py     # Main training script
â”‚   â”‚   â”œâ”€â”€ run_fixed_training.sh            # Training launcher
â”‚   â”‚   â””â”€â”€ monitor_training.py              # Training monitoring
â”‚   â”œâ”€â”€ data_processing/              # Data preprocessing scripts
â”‚   â”œâ”€â”€ setup_environment.py         # Environment setup
â”‚   â””â”€â”€ start_container.sh           # Docker container launcher
â”‚
â”œâ”€â”€ configs/                          # Configuration files
â”‚   â””â”€â”€ model_configs/               # Model configurations
â”‚       â””â”€â”€ qwen25_0.5b.yaml        # Qwen2.5-0.5B config
â”‚
â”œâ”€â”€ docs/                            # Documentation
â”‚   â”œâ”€â”€ METHODOLOGY.md               # Training methodology
â”‚   â”œâ”€â”€ TROUBLESHOOTING.md           # Common issues and solutions
â”‚   â”œâ”€â”€ guides/                      # User guides
â”‚   â”œâ”€â”€ reports/                     # Technical reports
â”‚   â””â”€â”€ technical_references/        # Technical documentation
â”‚
â””â”€â”€ experiments/                     # Training outputs (generated)
    â””â”€â”€ [experiment_name]/           # Individual experiment results
```

## ğŸ§¬ Core Algorithms

This repository includes **four core algorithms** developed collaboratively:

### ğŸ“ Japanese Text Processing (`00convert_ja.py`)
- Japanese text normalization and preprocessing
- Character encoding standardization
- Text cleaning and tokenization preparation

### ğŸ”„ Model Conversion (`01_convert_hf_to_nemo.py`)
- HuggingFace to NeMo format conversion
- Model checkpoint transformation
- Configuration adaptation

### âš¡ PEFT Training (`02_qwen25_peft.py`)
- **Parameter-Efficient Fine-Tuning** with LoRA
- Memory-optimized training approach
- Adapter-based model customization

### ğŸ¯ Standard Fine-tuning (`03_qwen25_sft.py`)
- Traditional supervised fine-tuning
- Full parameter optimization
- Comprehensive model adaptation

## ğŸ”¬ Training Methodology

### Model Configuration
- **Base Model**: Qwen2.5-0.5B (500M parameters)
- **Training Technique**: Continual learning with PEFT-LoRA
- **Framework**: NVIDIA NeMo 2.0 with optimized configurations
- **Target Language**: Japanese

### Optimized Training Settings
```python
# Learning rate optimization (resolved from previous issues)
learning_rate: 3e-4        # Increased from 1e-5 (30x improvement)
min_learning_rate: 3e-5    # Appropriate minimum threshold
warmup_steps: 200          # Extended warmup period
scheduler: CosineAnnealing  # Stable convergence

# Mixed precision training
plugins: bf16_mixed()      # Correct NeMo 2.0 implementation

# PEFT-LoRA configuration
rank: 16                   # Adaptation rank
alpha: 32                  # Scaling parameter
dropout: 0.1               # Regularization
```

### Performance Results
Current training demonstrates successful convergence:
```
Step   0: loss = 12.11, lr = 1.493e-06
Step  20: loss = 12.03, lr = 3.134e-05
Step  40: loss = 11.68, lr = 6.119e-05
Step  60: loss = 11.28, lr = 9.104e-05
Step  86: loss = 11.00, lr = 1.299e-04
```

## ğŸ› ï¸ Usage Guide

### 1. Environment Validation
```bash
# Check GPU and environment setup
python scripts/training/check_environment.py

# Expected output:
# âœ… Docker available: Docker version 24.0.7
# âœ… GPU available: NVIDIA GeForce RTX 4090
# âœ… CUDA available: 12.8
```

### 2. Quick Validation
```bash
# Run 50-step validation test
bash scripts/training/run_fixed_training.sh
# Select option: 2. Fresh start (for testing)
```

### 3. Full Training
```bash
# Run complete Japanese fine-tuning
bash scripts/training/run_fixed_training.sh
# Select option: 1. Clean checkpoints and restart
```

### 4. Algorithm Usage
```bash
# Japanese text preprocessing
python src/algorithms/00convert_ja.py --input input.txt --output processed.txt

# Model conversion
python src/algorithms/01_convert_hf_to_nemo.py --model_path qwen2.5-0.5b

# PEFT training
python src/algorithms/02_qwen25_peft.py --config configs/model_configs/qwen25_0.5b.yaml

# Standard fine-tuning
python src/algorithms/03_qwen25_sft.py --config configs/model_configs/qwen25_0.5b.yaml
```

## ğŸ“Š Workshop Outcomes

### âœ… Technical Achievements
- **Successful Integration**: Combined framework and algorithm approaches
- **Optimized Training**: Resolved learning rate and precision configuration issues
- **Stable Performance**: Consistent loss convergence with proper checkpointing
- **Comprehensive Documentation**: Complete troubleshooting and best practices

### ğŸ“ Educational Value
- **Hands-on Learning**: Step-by-step implementation guide
- **Real-world Solutions**: Production-ready training configurations
- **Collaborative Development**: Demonstrates effective team-based ML development
- **Best Practices**: Following NVIDIA NeMo 2.0 official recommendations

## ğŸ”§ Troubleshooting

### Common Issues Resolved
- âœ… **Learning Rate Scheduler Conflicts**: Proper CosineAnnealing configuration
- âœ… **Mixed Precision Issues**: Correct bf16_mixed() plugin usage
- âœ… **Checkpoint Recovery**: Clean restart mechanisms
- âœ… **CUDA Memory Management**: Optimized batch sizes and precision

For detailed troubleshooting, see [docs/TROUBLESHOOTING.md](docs/TROUBLESHOOTING.md).

## ğŸ¤ Contributors

This workshop is a collaborative effort between:
- **M1nG**: Framework architecture, documentation, and training optimization
- **Kosuke**: Core algorithms, preprocessing, and fine-tuning implementations

## ğŸ“š Citation

If you use this work in your research, please cite:

```bibtex
@misc{nemo2_qwen25_japanese_finetune_2024,
  title={NeMo 2.0 Qwen2.5B Japanese Fine-tuning Workshop: A Collaborative Approach to Parameter-Efficient Training},
  author={M1nG and Kosuke},
  year={2024},
  url={https://github.com/nvidiasamp/nemo2-qwen2.5b-japanese-finetune},
  note={Workshop materials for Japanese language model fine-tuning using NVIDIA NeMo 2.0}
}
```

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **NVIDIA NeMo Team** for the excellent NeMo 2.0 framework
- **Alibaba Qwen Team** for the Qwen2.5 base model
- **Japanese NLP Community** for preprocessing insights and datasets
- **Workshop Participants** for collaborative development and testing

---

**Status**: ğŸŸ¢ Workshop Complete | **Training**: âœ… Validated | **Documentation**: ğŸ“– Comprehensive

For detailed technical implementation, see [docs/METHODOLOGY.md](docs/METHODOLOGY.md).
For troubleshooting and solutions, see [docs/TROUBLESHOOTING.md](docs/TROUBLESHOOTING.md). 