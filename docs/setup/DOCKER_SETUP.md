# NeMo Framework Docker é…ç½®æŒ‡å—

## é‡è¦é…ç½®æ›´æ–°

æ ¹æ®NVIDIAå®˜æ–¹æ¨èï¼Œè¿è¡ŒNeMo Frameworkæ—¶éœ€è¦ç‰¹å®šçš„Dockerå‚æ•°ä»¥ç¡®ä¿æœ€ä½³æ€§èƒ½å’Œç¨³å®šæ€§ã€‚

## é—®é¢˜èƒŒæ™¯

NeMo 25.04å®¹å™¨ä¼šæ˜¾ç¤ºä»¥ä¸‹è­¦å‘Šï¼š
```
NOTE: The SHMEM allocation limit is set to the default of 64MB. This may be
   insufficient for NeMo Framework. NVIDIA recommends the use of the following flags:
   docker run --gpus all --ipc=host --ulimit memlock=-1 --ulimit stack=67108864 ...
```

## æ¨èçš„Dockerè¿è¡Œå‘½ä»¤

### é…ç½®éªŒè¯
```bash
docker run --rm --gpus all --ipc=host --ulimit memlock=-1 --ulimit stack=67108864 \
  -v $(pwd):/workspace -w /workspace \
  nvcr.io/nvidia/nemo:25.04 python scripts/test_training_config.py
```

### è®­ç»ƒæ‰§è¡Œ
```bash
docker run --rm --gpus all --ipc=host --ulimit memlock=-1 --ulimit stack=67108864 \
  -v $(pwd):/workspace -w /workspace \
  nvcr.io/nvidia/nemo:25.04 python continual_learning.py
```

## å‚æ•°è¯´æ˜

| å‚æ•° | ä½œç”¨ | é‡è¦æ€§ |
|------|------|--------|
| `--gpus all` | è®¿é—®æ‰€æœ‰GPU | å¿…éœ€ |
| `--ipc=host` | ä½¿ç”¨ä¸»æœºIPCå‘½åç©ºé—´ | **å…³é”®** - æé«˜å…±äº«å†…å­˜æ€§èƒ½ |
| `--ulimit memlock=-1` | å–æ¶ˆå†…å­˜é”å®šé™åˆ¶ | **å…³é”®** - é˜²æ­¢CUDAå†…å­˜åˆ†é…å¤±è´¥ |
| `--ulimit stack=67108864` | è®¾ç½®å †æ ˆå¤§å°ä¸º64MB | **é‡è¦** - æ”¯æŒå¤§å‹ç¥ç»ç½‘ç»œè®¡ç®—å›¾ |
| `-v $(pwd):/workspace` | æŒ‚è½½å½“å‰ç›®å½• | å¿…éœ€ |
| `-w /workspace` | è®¾ç½®å·¥ä½œç›®å½• | å¿…éœ€ |

## æŠ€æœ¯åŸç†

### IPC Hostæ¨¡å¼
- å…è®¸å®¹å™¨ä¸ä¸»æœºå…±äº«è¿›ç¨‹é—´é€šä¿¡
- å¯¹å¤šè¿›ç¨‹æ•°æ®åŠ è½½å’Œåˆ†å¸ƒå¼è®­ç»ƒè‡³å…³é‡è¦
- æé«˜å¤§å‹æ¨¡å‹è®­ç»ƒæ—¶çš„å†…å­˜è®¿é—®æ•ˆç‡

### å†…å­˜é”å®šé™åˆ¶ç§»é™¤
- é˜²æ­¢CUDAè¿è¡Œæ—¶å†…å­˜åˆ†é…å¤±è´¥
- ç‰¹åˆ«é‡è¦å¯¹äºGPUå¯†é›†å‹çš„æ·±åº¦å­¦ä¹ å·¥ä½œè´Ÿè½½
- é¿å…"failed to allocate memory"é”™è¯¯

### å †æ ˆå¤§å°å¢åŠ 
- æ”¯æŒæ·±åº¦ç¥ç»ç½‘ç»œçš„å¤§å‹è®¡ç®—å›¾
- é˜²æ­¢é€’å½’è°ƒç”¨æ ˆæº¢å‡º
- 64MBå †æ ˆå¤§å°è¶³ä»¥å¤„ç†å¤§å¤šæ•°NeMoæ¨¡å‹

## éªŒè¯é…ç½®

è¿è¡Œä»¥ä¸‹å‘½ä»¤éªŒè¯é…ç½®æ˜¯å¦æ­£ç¡®ï¼š

```bash
# æµ‹è¯•é…ç½®
docker run --rm --gpus all --ipc=host --ulimit memlock=-1 --ulimit stack=67108864 \
  -v $(pwd):/workspace -w /workspace \
  nvcr.io/nvidia/nemo:25.04 python scripts/test_training_config.py

# æœŸæœ›è¾“å‡ºï¼š
# ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼é…ç½®éªŒè¯æˆåŠŸ
# âœ… continual_learning.py å¯ä»¥å®‰å…¨è¿è¡Œ
```

## æ•…éšœæ’é™¤

å¦‚æœä»é‡åˆ°å†…å­˜ç›¸å…³é”™è¯¯ï¼Œå¯ä»¥è€ƒè™‘ï¼š

1. **å¢åŠ å…±äº«å†…å­˜å¤§å°**ï¼ˆå¦‚æœä¸»æœºå…è®¸ï¼‰ï¼š
   ```bash
   --shm-size=2g
   ```

2. **æ£€æŸ¥ä¸»æœºèµ„æº**ï¼š
   ```bash
   # æ£€æŸ¥å¯ç”¨å†…å­˜
   free -h
   
   # æ£€æŸ¥GPUçŠ¶æ€
   nvidia-smi
   ```

3. **å‡å°‘æ‰¹æ¬¡å¤§å°**ï¼š
   åœ¨è®­ç»ƒè„šæœ¬ä¸­è°ƒæ•´ `micro_batch_size` æˆ– `global_batch_size`

## æ›´æ–°å†å²

- **2025-07-14**: æ ¹æ®NeMo 25.04å®¹å™¨è­¦å‘Šæ›´æ–°Dockerå‚æ•°
- **ä¿®å¤å‰**: åŸºæœ¬å‚æ•° `docker run --rm --gpus all`
- **ä¿®å¤å**: å®Œæ•´å‚æ•°åŒ…å«IPCå’Œå†…å­˜é™åˆ¶é…ç½® 