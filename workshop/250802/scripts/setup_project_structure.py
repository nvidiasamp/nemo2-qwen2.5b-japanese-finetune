#!/usr/bin/env python3
"""
é¡¹ç›®ç›®å½•ç»“æ„è®¾ç½®è„šæœ¬
åŸºäºNeMo 2.0 + Qwen2.5-0.5Bæ—¥è¯­æŒç»­å­¦ä¹ Workshopé¡¹ç›®éœ€æ±‚
"""

import os
from pathlib import Path

def create_project_structure():
    """åˆ›å»ºå®Œæ•´çš„é¡¹ç›®ç›®å½•ç»“æ„"""
    
    # é¡¹ç›®æ ¹ç›®å½•
    project_root = Path(".")
    
    # å®šä¹‰ç›®å½•ç»“æ„
    directories = [
        # æ•°æ®ç›®å½•
        "data",
        "data/llm_jp_wiki",
        "data/llm_jp_wiki/processed",
        "data/llm_jp_wiki/nemo_format", 
        "data/llm_jp_wiki/nemo_binary",
        
        # æ¨¡å‹ç›®å½•
        "models",
        "models/checkpoints",
        "models/checkpoints/qwen25_continual",
        "models/checkpoints/qwen25_peft",
        
        # è„šæœ¬ç›®å½•
        "scripts",
        "scripts/data_processing",
        "scripts/training",
        "scripts/inference",
        "scripts/evaluation",
        
        # æ—¥å¿—ç›®å½•
        "logs",
        "logs/training",
        "logs/inference",
        "logs/data_processing",
        
        # æ–‡æ¡£ç›®å½•
        "docs",
        "docs/model_cards",
        "docs/api_docs", 
        "docs/user_guides",
        
        # é…ç½®ç›®å½•
        "configs",
        "configs/training",
        "configs/data",
        "configs/wandb",
        
        # è¾“å‡ºç›®å½•
        "outputs",
        "outputs/inference_results",
        "outputs/evaluation_reports",
        "outputs/demo_materials",
        
        # å·¥å…·ç›®å½•
        "tools",
        "tools/data_validation",
        "tools/model_analysis",
        "tools/demo_tools",
        
        # æµ‹è¯•ç›®å½•
        "tests",
        "tests/unit_tests",
        "tests/integration_tests",
        "tests/performance_tests"
    ]
    
    # åˆ›å»ºç›®å½•
    print("ğŸš€ åˆ›å»ºé¡¹ç›®ç›®å½•ç»“æ„...")
    for directory in directories:
        dir_path = project_root / directory
        dir_path.mkdir(parents=True, exist_ok=True)
        print(f"âœ… Created: {directory}")
    
    # åˆ›å»ºREADMEæ–‡ä»¶
    create_readme_files(project_root)
    
    # åˆ›å»ºé…ç½®æ–‡ä»¶æ¨¡æ¿
    create_config_templates(project_root)
    
    # åˆ›å»ºgitignore
    create_gitignore(project_root)
    
    print("\nğŸ‰ é¡¹ç›®ç›®å½•ç»“æ„åˆ›å»ºå®Œæˆï¼")
    print("ğŸ“ ä¸»è¦ç›®å½•ï¼š")
    print("   ğŸ“‚ data/          - æ•°æ®å­˜å‚¨")
    print("   ğŸ“‚ models/        - æ¨¡å‹å’Œcheckpoint")
    print("   ğŸ“‚ scripts/       - æ‰€æœ‰è„šæœ¬æ–‡ä»¶")
    print("   ğŸ“‚ logs/          - æ—¥å¿—æ–‡ä»¶")
    print("   ğŸ“‚ docs/          - æ–‡æ¡£")
    print("   ğŸ“‚ configs/       - é…ç½®æ–‡ä»¶")
    print("   ğŸ“‚ outputs/       - è¾“å‡ºç»“æœ")
    print("   ğŸ“‚ tools/         - å·¥å…·è„šæœ¬")
    print("   ğŸ“‚ tests/         - æµ‹è¯•æ–‡ä»¶")

def create_readme_files(project_root):
    """åˆ›å»ºå„ç›®å½•çš„READMEæ–‡ä»¶"""
    
    readme_contents = {
        "data/README.md": """# æ•°æ®ç›®å½•

## ç›®å½•ç»“æ„
- `llm_jp_wiki/` - LLM-JPæ—¥è¯­Wikipediaè¯­æ–™åº“
  - `processed/` - Uzushioé¢„å¤„ç†åçš„æ•°æ®
  - `nemo_format/` - NeMo Curatorå¤„ç†åçš„Parquetæ ¼å¼æ•°æ®
  - `nemo_binary/` - NeMoè®­ç»ƒç”¨äºŒè¿›åˆ¶æ ¼å¼æ•°æ®(.bin/.idx)

## æ•°æ®æµç¨‹
1. ä¸‹è½½LLM-JPæ•°æ® â†’ `llm_jp_wiki/`
2. Uzushioé¢„å¤„ç† â†’ `processed/`
3. NeMo Curatorå»é‡ â†’ `nemo_format/`
4. äºŒå€¼åŒ–å¤„ç† â†’ `nemo_binary/`
""",
        
        "models/README.md": """# æ¨¡å‹ç›®å½•

## ç›®å½•ç»“æ„
- `qwen25_0.5b.nemo` - å¯¼å…¥çš„åŸºç¡€æ¨¡å‹
- `checkpoints/` - è®­ç»ƒcheckpoint
  - `qwen25_continual/` - ç»§ç»­å­¦ä¹ checkpoint
  - `qwen25_peft/` - PEFT-LoRAå¾®è°ƒcheckpoint

## æ¨¡å‹æµç¨‹
1. HuggingFace â†’ NeMoæ ¼å¼ (`qwen25_0.5b.nemo`)
2. ç»§ç»­å­¦ä¹ è®­ç»ƒ â†’ `qwen25_continual/`
3. PEFTå¾®è°ƒ â†’ `qwen25_peft/`
""",
        
        "scripts/README.md": """# è„šæœ¬ç›®å½•

## æ ¸å¿ƒè„šæœ¬
1. `01_import_model.py` - æ¨¡å‹å¯¼å…¥
2. `02a_process_data_uzushio.py` - Uzushioæ•°æ®é¢„å¤„ç†
3. `02b_process_data_curator.py` - NeMo Curatoræ•°æ®å¤„ç†
4. `02c_binarize_data.py` - æ•°æ®äºŒå€¼åŒ–
5. `03_run_continual_learning.py` - ç»§ç»­å­¦ä¹ è®­ç»ƒ
6. `04_run_peft_tuning.py` - PEFTå¾®è°ƒ
7. `05_run_inference.py` - æ¨¡å‹æ¨ç†

## ç›®å½•è¯´æ˜
- `data_processing/` - æ•°æ®å¤„ç†ç›¸å…³è„šæœ¬
- `training/` - è®­ç»ƒç›¸å…³è„šæœ¬
- `inference/` - æ¨ç†ç›¸å…³è„šæœ¬
- `evaluation/` - è¯„ä¼°ç›¸å…³è„šæœ¬
""",
        
        "logs/README.md": """# æ—¥å¿—ç›®å½•

## ç›®å½•ç»“æ„
- `training/` - è®­ç»ƒæ—¥å¿—
- `inference/` - æ¨ç†æ—¥å¿—
- `data_processing/` - æ•°æ®å¤„ç†æ—¥å¿—

## æ—¥å¿—ç®¡ç†
- è‡ªåŠ¨æŒ‰æ—¥æœŸåˆ›å»ºå­ç›®å½•
- ä¿ç•™æœ€è¿‘30å¤©çš„æ—¥å¿—
- WandBé“¾æ¥è®°å½•åœ¨å¯¹åº”æ—¥å¿—ä¸­
""",
        
        "docs/README.md": """# æ–‡æ¡£ç›®å½•

## ç›®å½•ç»“æ„
- `model_cards/` - æ¨¡å‹å¡ç‰‡å’Œäº¤ä»˜æ–‡æ¡£
- `api_docs/` - APIæ–‡æ¡£
- `user_guides/` - ç”¨æˆ·æŒ‡å—

## äº¤ä»˜æ–‡æ¡£
- `MODEL_CARD.md` - æ¨¡å‹äº¤ä»˜å¡ç‰‡
- `USAGE_GUIDE.md` - ä½¿ç”¨æŒ‡å—
- `WANDB_LINKS.md` - WandBå®éªŒé“¾æ¥
"""
    }
    
    for file_path, content in readme_contents.items():
        readme_file = project_root / file_path
        with open(readme_file, 'w', encoding='utf-8') as f:
            f.write(content)
        print(f"ğŸ“„ Created: {file_path}")

def create_config_templates(project_root):
    """åˆ›å»ºé…ç½®æ–‡ä»¶æ¨¡æ¿"""
    
    # WandBé…ç½®æ¨¡æ¿
    wandb_config = """# WandBé…ç½®æ¨¡æ¿
# å›¢é˜Ÿä¿¡æ¯
entity: "your-team"

# é¡¹ç›®åç§°
projects:
  continual: "qwen25-japanese-continual"
  peft: "qwen25-japanese-peft"
  demo: "qwen25-demo-live"

# é€šç”¨æ ‡ç­¾
common_tags:
  - "nemo2.0"
  - "qwen2.5-0.5b"
  - "japanese"
  - "workshop"

# ç¯å¢ƒä¿¡æ¯
environment:
  gpu: "RTX_6000_Ada"
  container: "nemo:25.04"
  python: "3.10"
"""
    
    with open(project_root / "configs/wandb/wandb_config.yaml", 'w', encoding='utf-8') as f:
        f.write(wandb_config)
    
    # è®­ç»ƒé…ç½®æ¨¡æ¿
    training_config = """# è®­ç»ƒé…ç½®æ¨¡æ¿

# ç»§ç»­å­¦ä¹ é…ç½®
continual_learning:
  model: "qwen2.5-0.5b"
  max_steps: 1000
  micro_batch_size: 4
  global_batch_size: 64
  seq_length: 2048
  log_every_n_steps: 10

# PEFTé…ç½®
peft:
  scheme: "lora"
  max_steps: 500
  micro_batch_size: 4
  global_batch_size: 64
  seq_length: 2048
  log_every_n_steps: 5
  # PEFTç‰¹æ®Šé…ç½®
  ckpt_async_save: false
  context_parallel_size: 1
  ddp: "megatron"
"""
    
    with open(project_root / "configs/training/training_config.yaml", 'w', encoding='utf-8') as f:
        f.write(training_config)
    
    print(f"ğŸ“„ Created: configs/wandb/wandb_config.yaml")
    print(f"ğŸ“„ Created: configs/training/training_config.yaml")

def create_gitignore(project_root):
    """åˆ›å»º.gitignoreæ–‡ä»¶"""
    
    gitignore_content = """# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# Virtual Environment
venv/
env/
ENV/

# Jupyter Notebook
.ipynb_checkpoints

# PyCharm
.idea/

# VSCode
.vscode/

# Data files (too large for git)
data/llm_jp_wiki/
*.bin
*.idx
*.parquet

# Model files (too large for git)
models/*.nemo
models/checkpoints/

# Logs
logs/*.log
logs/**/*.log

# Temporary files
*.tmp
*.temp
.DS_Store
Thumbs.db

# WandB
wandb/

# Docker
.dockerignore

# Environment variables
.env
.env.local

# Outputs
outputs/inference_results/
outputs/evaluation_reports/

# Cache
.cache/
"""
    
    gitignore_file = project_root / ".gitignore"
    # è¯»å–ç°æœ‰å†…å®¹é¿å…é‡å¤
    existing_content = ""
    if gitignore_file.exists():
        with open(gitignore_file, 'r', encoding='utf-8') as f:
            existing_content = f.read()
    
    # åªæ·»åŠ æ–°å†…å®¹
    if "# Python" not in existing_content:
        with open(gitignore_file, 'a', encoding='utf-8') as f:
            f.write(gitignore_content)
        print(f"ğŸ“„ Updated: .gitignore")

if __name__ == "__main__":
    create_project_structure() 