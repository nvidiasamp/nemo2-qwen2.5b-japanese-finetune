# Task ID: 3
# Title: LLM-JP日语语料库下载与Uzushio预处理
# Status: pending
# Dependencies: 1
# Priority: high
# Description: 从LLM-JP GitLab仓库下载日语Wikipedia v3语料库，并使用Uzushio工具进行初步的清洗和过滤，为0.5B模型准备适量的高质量数据。
# Details:
创建一个脚本 `scripts/02a_process_data_uzushio.py`。
1. 使用 `git sparse-checkout` 只下载 `ja/ja_wiki` 部分以节省空间和时间。
2. 调用Uzushio对下载的原始数据进行处理。
```python
# scripts/02a_process_data_uzushio.py
import subprocess
from pathlib import Path
from uzushio.main import main as uzushio_main

data_dir = Path("./data/llm_jp_wiki")
# ... (git clone 和 sparse-checkout 代码) ...

uzushio_config = {
    "input_dir": str(data_dir / "ja/ja_wiki"),
    "output_dir": str(data_dir / "processed"),
    "max_docs": 100000,  # 限制文档数量，适合0.5B模型
    "min_text_length": 100,
    "language": "ja",
    "num_workers": 4
}
uzushio_main(**uzushio_config)
```

# Test Strategy:
脚本执行成功，在 `./data/llm_jp_wiki/processed` 目录下生成处理后的 `jsonl` 文件。检查文件内容是否为清洗后的日语文本。

# Subtasks:
## 1. 配置并执行sparse-checkout下载 [pending]
### Dependencies: None
### Description: 使用Git的sparse-checkout功能，仅下载所需的数据子目录或文件，避免拉取整个大型仓库。
### Details:
包括初始化本地仓库、配置sparse-checkout模式、编辑.git/info/sparse-checkout文件指定需要的路径，并执行拉取操作。

## 2. 安装并配置Uzushio [pending]
### Dependencies: 3.1
### Description: 在本地环境中安装Uzushio工具，并完成相关依赖配置，确保其可用于后续数据处理。
### Details:
根据Uzushio官方文档或项目说明，完成软件包安装、环境变量设置及依赖库配置。

## 3. 编写数据处理脚本 [pending]
### Dependencies: 3.2
### Description: 开发脚本对下载的数据进行预处理，包括格式转换、数据清洗等操作，以满足后续分析需求。
### Details:
根据数据特点和预处理需求，选择合适的编程语言和库，编写并测试数据处理脚本。

## 4. 验证清洗后数据质量 [pending]
### Dependencies: 3.3
### Description: 对经过预处理的数据进行质量检查，确保数据完整性、准确性和可用性。
### Details:
设计并执行数据质量验证流程，包括缺失值检测、格式一致性检查及样本抽查等。

