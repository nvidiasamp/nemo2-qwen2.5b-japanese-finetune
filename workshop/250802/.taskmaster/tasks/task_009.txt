# Task ID: 9
# Title: 构建PEFT-LoRA微调脚本
# Status: pending
# Dependencies: 8
# Priority: high
# Description: 基于NeMo 2.0的recipe系统，编写PEFT-LoRA微调脚本。脚本使用`llm.qwen25_500m.finetune_recipe`，并加载上一阶段继续学习产出的模型checkpoint。
# Details:
创建脚本 `scripts/04_run_peft_tuning.py`。
```python
# scripts/04_run_peft_tuning.py
import nemo_run as run
from nemo.collections import llm
from nemo import lightning as nl

def setup_peft_training():
    recipe = llm.qwen25_500m.finetune_recipe(
        dir="./models/checkpoints/qwen25_peft",
        name="japanese_lora",
        peft_scheme="lora"
    )
    # 恢复继续学习后的模型
    recipe.model.restore_from_path = './models/checkpoints/qwen25_continual/checkpoints/last.nemo' # 指向正确的checkpoint
    # 官方要求的PEFT特殊配置
    recipe.trainer.strategy.ckpt_async_save = False
    recipe.trainer.strategy.context_parallel_size = 1
    recipe.trainer.strategy.ddp = "megatron"
    recipe.trainer.max_steps = 500
    # ... (配置微调数据) ...
    return recipe
```

# Test Strategy:
脚本可以无报错地初始化PEFT recipe对象。所有关键配置（peft_scheme, ckpt_async_save等）均已正确设置。
