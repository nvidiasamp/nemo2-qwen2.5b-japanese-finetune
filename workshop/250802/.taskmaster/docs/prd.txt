# äº§å“éœ€æ±‚æ–‡æ¡£ (PRD)
# åŸºäºNeMo2.0çš„Qwen2.5-0.5Bæ—¥è¯­æŒç»­å­¦ä¹ ä¸é«˜æ•ˆå¾®è°ƒå®è·µ
# Workshopé¡¹ç›®ï¼šPEFTã€SFTã€DPOçš„åº”ç”¨

## 1. é¡¹ç›®æ¦‚è¿°

### 1.1 é¡¹ç›®èƒŒæ™¯ï¼ˆ0.5Bæ¨¡å‹workshopç‰¹åŒ–ç‰ˆï¼‰
ä½œä¸ºNVIDIAå­¦ç”Ÿå¤§ä½¿ï¼Œå¼€å±•åŸºäºNeMo2.0æ¡†æ¶çš„Qwen2.5-0.5Bæ¨¡å‹æ—¥è¯­æŒç»­å­¦ä¹ ä¸é«˜æ•ˆå¾®è°ƒå®è·µworkshopã€‚

**ğŸ¯ é‡è¦å®šä½**ï¼šæœ¬é¡¹ç›®ä¸“é—¨é’ˆå¯¹0.5Bå°å‹æ¨¡å‹ä¼˜åŒ–ï¼Œå¼ºè°ƒ**æ–¹æ³•è®ºæ•™å­¦ä»·å€¼**è€Œéå¤§æ¨¡å‹çº§åˆ«çš„æ•ˆæœå±•ç¤ºã€‚

### 1.2 é¡¹ç›®ç›®æ ‡ï¼ˆé‡æ–°æ ¡å‡†ï¼‰
- **ä¸»è¦ç›®æ ‡**: å±•ç¤ºNeMo2.0æ¡†æ¶çš„ä½¿ç”¨æ–¹æ³•å’ŒæŠ€æœ¯æµç¨‹
- **æ ¸å¿ƒä»·å€¼**: 0.5Bæ¨¡å‹çš„å¿«é€Ÿè¿­ä»£å’Œæ•™å­¦å‹å¥½ç‰¹æ€§
- **æŠ€æœ¯æ¼”ç¤º**: ç»§ç»­å­¦ä¹ â†’PEFTå®Œæ•´é“¾è·¯å®ç°
- **å›¢é˜Ÿåä½œ**: ä¸SFT/DPOå›¢é˜Ÿçš„æ ‡å‡†åŒ–æ¨¡å‹äº¤ä»˜
- **WandBé›†æˆ**: ç»Ÿä¸€ç›‘æ§å’Œå›¢é˜Ÿåä½œå±•ç¤º
- **ç°å®æœŸæœ›**: é‡è§†æŠ€æœ¯æ–¹æ³• > ç”Ÿæˆæ•ˆæœè´¨é‡

### 1.3 ç›®æ ‡æ¨¡å‹
- **ä¸»è¦æ¨¡å‹**: Qwen2.5-0.5Bï¼ˆé€‚åˆå®è·µæ•™å­¦çš„å°å‹æ¨¡å‹ï¼‰
- **é€‰æ‹©ç†ç”±**: åœ¨æœ‰é™è®¡ç®—èµ„æºä¸‹ä»èƒ½é«˜æ•ˆå­¦ä¹ 
- **å®šåˆ¶åŒ–**: ä½¿ç”¨æ—¥è¯­è¯­æ–™åº“è¿›è¡ŒæŒç»­å­¦ä¹ 

### 1.4 é¡¹ç›®æ—¶é—´çº¿ï¼ˆåŸºäº0.5Bæ¨¡å‹ç‰¹æ€§ä¼˜åŒ–ï¼‰
- **é¡¹ç›®å‘¨æœŸ**: 2025å¹´7æœˆ9æ—¥ - 2025å¹´7æœˆ23æ—¥ (14å¤©)
- **å½“å‰æ—¥æœŸ**: 2025å¹´7æœˆ9æ—¥ 18:18 JSTï¼ˆé¡¹ç›®æ­£å¼å¼€å§‹ï¼ï¼‰
- **æ¼”ç¤ºæ—¥æœŸ**: 2025å¹´7æœˆ23æ—¥
- **æ¼”ç¤ºæ—¶é•¿**: 20åˆ†é’Ÿï¼ˆä½ 10åˆ†é’Ÿ + é˜Ÿå‹10åˆ†é’Ÿï¼‰
- **å‰©ä½™æ—¶é—´**: 14å¤©æ•´

**ğŸ¯ åŸºäº0.5Bæ¨¡å‹ä¼˜åŒ–çš„ç°å®æ—¶é—´ä¼°ç®—**ï¼š
- **æ¨¡å‹å¯¼å…¥**: 5-10åˆ†é’Ÿï¼ˆä¸€æ¬¡æ€§æ“ä½œï¼‰
- **ç»§ç»­å­¦ä¹ è®­ç»ƒ**: 1-2å°æ—¶ï¼ˆ0.5Bæ¨¡å‹è®­ç»ƒå¾ˆå¿«ï¼‰
- **LoRAå¾®è°ƒ**: 30-60åˆ†é’Ÿï¼ˆå‚æ•°é‡å°ï¼Œæ”¶æ•›å¿«ï¼‰
- **æ¨ç†æ¼”ç¤º**: æ¯æ¬¡<10ç§’ï¼ˆ0.5Bæ¨¡å‹æ¨ç†é€Ÿåº¦å¿«ï¼‰
- **é‡ç‚¹æ—¶é—´**: æ›´å¤šæ—¶é—´ç”¨äºæ¼”ç¤ºå‡†å¤‡å’Œæ–¹æ³•è®ºå±•ç¤º

## 2. æŠ€æœ¯è§„æ ¼

## âœ… **é‡è¦çº æ­£ï¼šNeMo 2.0çš„å®é™…ä½¿ç”¨æ–¹å¼**

**ğŸ¯ åŸºäºå®˜æ–¹æ–‡æ¡£éªŒè¯çš„æ­£ç¡®æŠ€æœ¯è·¯çº¿**ï¼š

| æ–¹é¢ | NeMo 1.0 | NeMo 2.0ï¼ˆå®˜æ–¹éªŒè¯ï¼‰ | å½±å“ |
|------|----------|---------------------|------|
| **é…ç½®æ–¹å¼** | YAMLé…ç½®æ–‡ä»¶ | **NeMo-Run + recipeç³»ç»Ÿ** | å®Œå…¨ä¸åŒ |
| **æ‰§è¡Œæ–¹å¼** | ç›´æ¥è„šæœ¬æ‰§è¡Œ | **`run.run()` + `if __name__ == "__main__":`** | å¿…é¡»æ›´æ”¹ |
| **æ¨¡å‹é…ç½®** | ä¼ ç»Ÿcheckpoint | **`llm.qwen25_500m.finetune_recipe()`** | ä½¿ç”¨recipe |
| **æ•°æ®é…ç½®** | YAMLæ•°æ®é…ç½® | **`run.Config(DataModule, ...)`** | å¯¹è±¡åŒ–é…ç½® |
| **PEFTé…ç½®** | YAMLä¸­é…ç½®LoRA | **recipeä¸­`peft_scheme="lora"`** | ç®€åŒ–ä½†å›ºå®š |
| **è®­ç»ƒå¯åŠ¨** | ç›´æ¥pythonå‘½ä»¤ | **`run.run(recipe, executor=run.LocalExecutor())`** | ç»Ÿä¸€æ‰§è¡Œå™¨ |

**ğŸ“‹ å®˜æ–¹æ–‡æ¡£éªŒè¯è¦ç‚¹**ï¼š
- âœ… **Qwen2.5-0.5Bæ”¯æŒ**: å®˜æ–¹ç¡®è®¤æ”¯æŒçŠ¶æ€ä¸º"Yes"
- âœ… **recipeæ­£ç¡®å‘½å**: ä½¿ç”¨`llm.qwen25_500m`ï¼ˆå®˜æ–¹æ–‡æ¡£recipeåˆ—è¡¨éªŒè¯ï¼‰
- âœ… **å¿…éœ€çš„ifæ¡ä»¶**: `if __name__ == "__main__":` æ˜¯å®˜æ–¹è¦æ±‚
- âœ… **PEFTç‰¹æ®Šé…ç½®**: å¿…éœ€`ckpt_async_save=False`, `ddp="megatron"`, `context_parallel_size=1`
- âœ… **WandBé›†æˆ**: é€šè¿‡`lightning.pytorch.loggers.WandbLogger`

**ğŸ¯ åŸºäºå®˜æ–¹éªŒè¯çš„æ­£ç¡®æŠ€æœ¯è·¯çº¿**ï¼š
- **è®­ç»ƒæ–¹å¼**: NeMo-Run + recipeç³»ç»Ÿï¼ˆè¿™æ˜¯å”¯ä¸€æ­£ç¡®çš„æ–¹å¼ï¼‰
- **æ¨¡å‹ç®¡ç†**: æœ¬åœ°ä¸‹è½½0.5Bæ¨¡å‹ï¼ˆçº¦1-2GBï¼‰
- **é…ç½®æ–¹å¼**: `run.Config` + recipeä¿®æ”¹
- **æ‰§è¡Œæ–¹å¼**: `run.run()` ç»Ÿä¸€æ‰§è¡Œ
- **æ¨ç†æ–¹å¼**: `api.generate()` ç›´æ¥è°ƒç”¨

### 2.1 ç¯å¢ƒè¦æ±‚
- **å®¹å™¨**: NVIDIA NeMo 25.04 Dockerå®¹å™¨ (nvcr.io/nvidia/nemo:25.04)
- **GPU**: NVIDIA RTX 6000 Ada Generationï¼ˆ49140MiBæ˜¾å­˜ï¼‰
- **æ¡†æ¶**: NeMo 2.0 + NeMo-Runï¼ˆå¿…éœ€ï¼‰
- **ç›‘æ§å·¥å…·**: WandB (Weights & Biases)
- **å½“å‰çŠ¶æ€**: å·²ä¸‹è½½NeMo 25.04å®¹å™¨ï¼ˆ59.7GBï¼‰
- **âœ… æ¨¡å‹ç­–ç•¥**: æœ¬åœ°ä¸‹è½½Qwen2.5-0.5Bï¼ˆçº¦1-2GBï¼‰ï¼Œä¾¿äºè°ƒè¯•å’Œå¿«é€Ÿè¿­ä»£

### 2.2 æ•°æ®é›†ï¼ˆåŸºäºLLM-JPä¸“ä¸šè¯­æ–™åº“ï¼‰
- **æ•°æ®æ¥æº**: LLM-JPæ—¥è¯­Wikipediaè¯­æ–™åº“ v3ï¼ˆä¸“ä¸šé«˜è´¨é‡ï¼‰
  - **æ•°æ®åœ°å€**: https://gitlab.llm-jp.nii.ac.jp/datasets/llm-jp-corpus-v3/-/tree/main/ja/ja_wiki
  - **æ•°æ®æœºæ„**: å›½ç«‹æƒ…æŠ¥å­¦ç ”ç©¶æ‰€ï¼ˆNIIï¼‰LLM-JPé¡¹ç›®ç»„
  - **æ•°æ®è´¨é‡**: ä¸“ä¸šæ¸…æ´—å’Œé¢„å¤„ç†çš„æ—¥è¯­Wikipediaè¯­æ–™
- **æ‰€éœ€æ ¼å¼**: NeMoæ ‡å‡†äºŒè¿›åˆ¶æ ¼å¼
  - `train_text_document.bin` / `train_text_document.idx`
  - `validation_text_document.bin` / `validation_text_document.idx`
- **æ•°æ®è§„æ¨¡**: é’ˆå¯¹0.5Bæ¨¡å‹çš„åˆç†å­é›†ï¼ˆé¢„è®¡1-5GBå¤„ç†åæ•°æ®ï¼‰
- **é¢„å¤„ç†å·¥å…·é“¾**: 
  - **ä¸»è¦å·¥å…·**: NeMo Curator + Uzushioï¼ˆåŸºäºApache Sparkï¼‰
  - **å¤„ç†ä¼˜åŠ¿**: GPUåŠ é€Ÿ + åˆ†å¸ƒå¼å¤„ç†
  - **0.5Bä¼˜åŒ–**: è™½ç„¶ä½¿ç”¨ä¼ä¸šçº§å·¥å…·ï¼Œä½†å¤„ç†çš„æ•°æ®é‡é€‚ä¸­

### 2.3 æ¨¡å‹å¯¼å…¥ä¸é…ç½® (åŸºäºå®˜æ–¹æ–‡æ¡£éªŒè¯çš„æ­£ç¡®æ–¹å¼)

#### 2.3.1 æ¨¡å‹æœ¬åœ°ä¸‹è½½ï¼ˆå®˜æ–¹æ–‡æ¡£éªŒè¯ï¼‰
```python
# âœ… å®˜æ–¹æ–‡æ¡£éªŒè¯çš„æ­£ç¡®å¯¼å…¥æ–¹å¼
from nemo.collections import llm

# ä¸€æ¬¡æ€§æ¨¡å‹å¯¼å…¥åˆ°æœ¬åœ°ï¼ˆå®˜æ–¹æ–‡æ¡£éªŒè¯ï¼‰
if __name__ == "__main__":  # å®˜æ–¹è¦æ±‚å¿…éœ€
    llm.import_ckpt(
        model=llm.Qwen2Model(llm.Qwen25Config500M()),  # å®˜æ–¹æ–‡æ¡£é…ç½®
        source='hf://Qwen/Qwen2.5-0.5B',
        output_path='./models/qwen25_0.5b',
        overwrite=False
    )
```

#### 2.3.2 ç»§ç»­å­¦ä¹ é…ç½®ï¼ˆåŸºäºå®˜æ–¹recipeï¼‰
```python
# âœ… åŸºäºå®˜æ–¹æ–‡æ¡£éªŒè¯çš„ç»§ç»­å­¦ä¹ é…ç½®
import nemo_run as run
from nemo.collections import llm

# ä½¿ç”¨å®˜æ–¹éªŒè¯çš„0.5B pretraining recipe
continual_recipe = llm.qwen25_500m.pretrain_recipe(  # å®˜æ–¹æ–‡æ¡£recipeåˆ—è¡¨éªŒè¯çš„æ­£ç¡®å‘½å
    dir="./models/checkpoints/qwen25_continual",
    name="japanese_continual_learning",
    num_nodes=1,
    num_gpus_per_node=1,
)

# é…ç½®ç»§ç»­å­¦ä¹ çš„æ•°æ®ï¼ˆLLM-JPå¤„ç†åçš„æ•°æ®ï¼‰
continual_recipe.data = run.Config(
    llm.PreTrainingDataModule,
    paths={
        'train': ['./data/llm_jp_wiki/nemo_binary/ja_wiki_train_text_document'],
        'validation': ['./data/llm_jp_wiki/nemo_binary/ja_wiki_validation_text_document'],
        'test': ['./data/llm_jp_wiki/nemo_binary/ja_wiki_validation_text_document']
    },
    seq_length=2048,
    micro_batch_size=4,     # 0.5Bæ¨¡å‹å¯ä»¥å¢åŠ batch size
    global_batch_size=64,   # åˆ©ç”¨49GBæ˜¾å­˜ä¼˜åŠ¿
    num_workers=4,
    pin_memory=True,
    dataset_kwargs={
        "index_mapping_dir": "./data/llm_jp_wiki/nemo_binary/",
        "data_impl": "mmap"
    }
)

continual_recipe.trainer.max_steps = 1000

# âš ï¸ å®˜æ–¹è¦æ±‚ï¼šå¿…é¡»åœ¨ if __name__ == "__main__": ä¸­æ‰§è¡Œ
if __name__ == "__main__":
    run.run(continual_recipe, executor=run.LocalExecutor())
```

#### 2.3.3 PEFTå¾®è°ƒé…ç½®ï¼ˆåŸºäºå®˜æ–¹éªŒè¯ï¼‰
```python
# âœ… åŸºäºå®˜æ–¹æ–‡æ¡£éªŒè¯çš„PEFTé…ç½®
import nemo_run as run
from nemo.collections import llm
from nemo import lightning as nl

# ä½¿ç”¨å®˜æ–¹éªŒè¯çš„0.5B finetune recipe
peft_recipe = llm.qwen25_500m.finetune_recipe(  # å®˜æ–¹æ–‡æ¡£recipeåˆ—è¡¨éªŒè¯çš„æ­£ç¡®å‘½å
    dir="./models/checkpoints/qwen25_peft",
    name="japanese_lora",
    num_nodes=1,
    num_gpus_per_node=1,
    peft_scheme="lora",  # å¯ç”¨LoRA
)

# æ¢å¤ç»§ç»­å­¦ä¹ åçš„æ¨¡å‹
peft_recipe.resume.restore_config = run.Config(
    nl.RestoreConfig,
    path='./models/checkpoints/qwen25_continual'  # ç»§ç»­å­¦ä¹ çš„checkpoint
)

# å®˜æ–¹éªŒè¯çš„å…³é”®PEFTé…ç½®
peft_recipe.trainer.max_steps = 500
peft_recipe.trainer.strategy.ckpt_async_save = False  # å®˜æ–¹è¦æ±‚ï¼šPEFTå¿…éœ€
peft_recipe.trainer.strategy.context_parallel_size = 1  # å®˜æ–¹è¦æ±‚ï¼šå¿…éœ€è®¾ç½®ä¸º1
peft_recipe.trainer.strategy.ddp = "megatron"  # å®˜æ–¹è¦æ±‚ï¼šLoRA/PEFTå¿…éœ€

# âš ï¸ å®˜æ–¹è¦æ±‚ï¼šå¿…é¡»åœ¨ if __name__ == "__main__": ä¸­æ‰§è¡Œ
if __name__ == "__main__":
    run.run(peft_recipe, executor=run.LocalExecutor())
```

## ğŸ” **Sampleä»£ç åˆ†æä¸å®˜æ–¹æ–‡æ¡£éªŒè¯æ€»ç»“**

### âœ… **Sampleä»£ç å®Œå…¨éªŒè¯çš„éƒ¨åˆ†**ï¼š
1. **recipeå‘½å**: ä½¿ç”¨ `llm.qwen25_500m.finetune_recipe()` (å®˜æ–¹æ–‡æ¡£recipeåˆ—è¡¨éªŒè¯)
2. **PEFTç‰¹æ®Šé…ç½®**: å®Œå…¨ä¸€è‡´çš„å¿…éœ€é…ç½®
   - `ckpt_async_save = False`
   - `context_parallel_size = 1`  
   - `ddp = "megatron"`
3. **MegatronStrategyé…ç½®**: æ¨ç†é…ç½®å®Œå…¨ä¸€è‡´
4. **ä»£ç ç»“æ„**: éƒ½ä½¿ç”¨ `if __name__ == "__main__":` è¦æ±‚
5. **æ‰§è¡Œæ–¹å¼**: é€šè¿‡ `run.run(recipe, executor=run.LocalExecutor())`

### ğŸ”§ **Sampleä»£ç çš„å±€é™æ€§**ï¼š
**Sampleä»£ç æœªåŒ…å«WandBé›†æˆ** - è¿™æ˜¯ç®€åŒ–ç‰ˆæœ¬ï¼Œä¸“æ³¨äºæ ¸å¿ƒPEFTåŠŸèƒ½æ¼”ç¤ºã€‚

### âœ… **åŸºäºå®˜æ–¹æ–‡æ¡£éªŒè¯çš„WandBé›†æˆ**ï¼š
å®˜æ–¹NeMo 2.0æ–‡æ¡£æ˜ç¡®æ”¯æŒé€šè¿‡ `lightning.pytorch.loggers.WandbLogger` é›†æˆï¼š

```python
# âœ… å®˜æ–¹æ–‡æ¡£éªŒè¯çš„æ­£ç¡®WandBé›†æˆæ–¹å¼
from lightning.pytorch.loggers import WandbLogger
from nemo.lightning import NeMoLogger

wandb_logger = WandbLogger(
    project="qwen25-japanese-continual",
    name="continual-learning-phase", 
    entity="your-team",
)

nemo_logger = NeMoLogger(
    wandb=wandb_logger,
    log_dir='./logs',
    name='experiment'
)

# é›†æˆåˆ°recipe trainerä¸­
recipe.trainer.logger = nemo_logger
```

**ğŸ“‹ ç»“è®º**: Sampleä»£ç æä¾›äº†æ ¸å¿ƒPEFTå®ç°çš„solid foundationï¼ŒPRDä¸­çš„WandBé›†æˆæ˜¯åŸºäºå®˜æ–¹æ–‡æ¡£çš„æ­£ç¡®è¡¥å……ã€‚

**ğŸ¯ æœ€ç»ˆRecipeå‘½åæ¾„æ¸…**:
- **Sampleä»£ç ä½¿ç”¨**: `llm.qwen2_7b.finetune_recipe()` (é’ˆå¯¹7Bæ¨¡å‹)
- **ä½ çš„é¡¹ç›®åº”ä½¿ç”¨**: `llm.qwen25_500m.finetune_recipe()` (é’ˆå¯¹Qwen2.5-0.5B)
- **å‘½åè§„å¾‹**: `qwen2_xxx` = Qwen2ç³»åˆ—, `qwen25_xxx` = Qwen2.5ç³»åˆ—
- **å®˜æ–¹ç¡®è®¤**: recipeåˆ—è¡¨æ˜ç¡®åŒ…å« `qwen25_500m`

## 3. å›¢é˜ŸèŒè´£åˆ†å·¥

### 3.1 èŒè´£åˆ’åˆ†
- **ç»§ç»­å­¦ä¹  + PEFT**: è´Ÿè´£äºº - ä½ 
  - æ—¥è¯­Wikipediaæ•°æ®é¢„å¤„ç†
  - ç»§ç»­å­¦ä¹ è®­ç»ƒå®ç°
  - LoRAå¾®è°ƒå®ç°
  - WandBç›‘æ§é›†æˆ
  
- **SFTï¼ˆç›‘ç£å¾®è°ƒï¼‰**: å…¶ä»–å›¢é˜Ÿæˆå‘˜
  - æŒ‡ä»¤è·Ÿéšæ•°æ®å‡†å¤‡
  - ç›‘ç£å¾®è°ƒå®ç°
  - æ€§èƒ½è¯„ä¼°
  
- **DPOï¼ˆç›´æ¥åå¥½ä¼˜åŒ–ï¼‰**: å…¶ä»–å›¢é˜Ÿæˆå‘˜
  - åå¥½æ•°æ®å‡†å¤‡
  - DPOè®­ç»ƒå®ç°
  - æœ€ç»ˆæ¨¡å‹ä¼˜åŒ–

### 3.2 å›¢é˜Ÿåä½œæ¥å£
- **æ¨¡å‹äº¤ä»˜æ ‡å‡†**: ç»Ÿä¸€çš„æ¨¡å‹æ ¼å¼å’Œæ–‡æ¡£è§„èŒƒ
- **è¿›åº¦åŒæ­¥**: å…±äº«WandBé¡¹ç›®dashboard
- **æŠ€æœ¯æ²Ÿé€š**: æ¯æ—¥åŒæ­¥ä¼šè®®å’ŒæŠ€æœ¯é—®é¢˜è®¨è®º
- **æ¼”ç¤ºåè°ƒ**: å„éƒ¨åˆ†æ¼”ç¤ºå†…å®¹çš„æ•´åˆ

## 4. å®æ–½é˜¶æ®µï¼ˆ14å¤©å†²åˆºï¼ŒåŸºäº0.5Bæ¨¡å‹ç‰¹æ€§ä¼˜åŒ–ï¼‰

### 4.1 ç¬¬ä¸€å‘¨ï¼šæ ¸å¿ƒåŠŸèƒ½å¿«é€Ÿå®ç° (2025/7/9-7/15)

#### Day 1 (7/9): ç¯å¢ƒä¸åŸºç¡€å‡†å¤‡ï¼ˆæ•°æ®é¢„å¤„ç†å¹¶è¡Œï¼‰
- **ä»»åŠ¡1.1**: NeMo 2.0å®¹å™¨ç¯å¢ƒéªŒè¯ï¼ˆ2å°æ—¶ï¼‰
- **ä»»åŠ¡1.2**: LLM-JPæ•°æ®ä¸‹è½½ä¸é¢„å¤„ç†å¯åŠ¨ï¼ˆå¹¶è¡Œè¿›è¡Œ5-7å°æ—¶ï¼‰
  - ä¸‹è½½LLM-JP Wikipedia v3æ•°æ®ï¼ˆ30-60åˆ†é’Ÿï¼‰
  - å¯åŠ¨Uzushio + NeMo Curatorå¤„ç†æµç¨‹ï¼ˆåå°è¿è¡Œï¼‰
- **ä»»åŠ¡1.3**: Qwen2.5-0.5Bæ¨¡å‹å¯¼å…¥ï¼ˆ10åˆ†é’Ÿï¼‰
- **ä»»åŠ¡1.4**: WandBåŸºç¡€é…ç½®ï¼ˆ1å°æ—¶ï¼‰
- **ä»»åŠ¡1.5**: é¢„å¤„ç†ç›‘æ§ä¸éªŒè¯ï¼ˆå®šæœŸæ£€æŸ¥ï¼‰

#### Day 2 (7/10): ç»§ç»­å­¦ä¹ éªŒè¯ 
- **ä»»åŠ¡2.1**: ç»§ç»­å­¦ä¹ è®­ç»ƒæµ‹è¯•ï¼ˆ1-2å°æ—¶è®­ç»ƒï¼‰
- **ä»»åŠ¡2.2**: åŸºç¡€æ¨ç†éªŒè¯ï¼ˆå¿«é€Ÿæµ‹è¯•ï¼‰
- **ä»»åŠ¡2.3**: WandBç›‘æ§é›†æˆéªŒè¯
- **ä»»åŠ¡2.4**: è®­ç»ƒpipelineè°ƒè¯•ä¼˜åŒ–

#### Day 3 (7/11): PEFT-LoRAå®ç°
- **ä»»åŠ¡3.1**: LoRAé…ç½®å’Œæµ‹è¯•ï¼ˆ30-60åˆ†é’Ÿè®­ç»ƒï¼‰
- **ä»»åŠ¡3.2**: æ¨ç†æ•ˆæœå¯¹æ¯”
- **ä»»åŠ¡3.3**: åŸºç¡€æ¼”ç¤ºå†…å®¹å‡†å¤‡
- **ä»»åŠ¡3.4**: æŠ€æœ¯æ–‡æ¡£è®°å½•

#### Day 4-7 (7/12-7/15): æ¼”ç¤ºä¼˜åŒ–ä¸å†…å®¹å‡†å¤‡
- **ä»»åŠ¡4.1**: å¤šç»„å®éªŒå¯¹æ¯”ï¼ˆ0.5Bæ¨¡å‹å¿«é€Ÿè¿­ä»£ä¼˜åŠ¿ï¼‰
- **ä»»åŠ¡4.2**: æ¼”ç¤ºè„šæœ¬ç¼–å†™å’Œæµ‹è¯•
- **ä»»åŠ¡4.3**: æŠ€æœ¯äº®ç‚¹æ€»ç»“
- **ä»»åŠ¡4.4**: WandBæ¼”ç¤ºé¢æ¿ä¼˜åŒ–

### 4.2 ç¬¬äºŒå‘¨ï¼šæ¼”ç¤ºå‡†å¤‡ä¸å›¢é˜Ÿåä½œ (2025/7/16-7/23)

#### Day 8-10 (7/16-7/18): å›¢é˜Ÿåä½œä¸æ¨¡å‹äº¤ä»˜
- **ä»»åŠ¡5.1**: æ¨¡å‹æ ‡å‡†åŒ–äº¤ä»˜ç»™SFT/DPOå›¢é˜Ÿï¼ˆç®€åŒ–æ ¼å¼ï¼‰
- **ä»»åŠ¡5.2**: æŠ€æœ¯æ–‡æ¡£å’Œä½¿ç”¨è¯´æ˜ç¼–å†™
- **ä»»åŠ¡5.3**: WandBæƒé™å…±äº«å’Œæ¼”ç¤ºé¢æ¿å‡†å¤‡
- **ä»»åŠ¡5.4**: 0.5Bæ¨¡å‹æ•ˆæœè¾¹ç•Œè¯´æ˜ï¼ˆå®äº‹æ±‚æ˜¯ï¼‰

#### Day 11-12 (7/19-7/20): æ¼”ç¤ºå†…å®¹ç²¾åŒ–
- **ä»»åŠ¡6.1**: æ¼”ç¤ºé‡ç‚¹ç¡®å®šï¼šæ–¹æ³•è®º > æ¨¡å‹æ•ˆæœ
- **ä»»åŠ¡6.2**: 10åˆ†é’Ÿæ¼”ç¤ºè„šæœ¬å®Œå–„
- **ä»»åŠ¡6.3**: æŠ€æœ¯äº®ç‚¹æç‚¼ï¼ˆNeMo 2.0ä½¿ç”¨æ–¹æ³•ï¼‰
- **ä»»åŠ¡6.4**: å¤‡ç”¨æ¼”ç¤ºæ–¹æ¡ˆå‡†å¤‡

#### Day 13-14 (7/21-7/23): æœ€ç»ˆå‡†å¤‡ä¸æ’ç»ƒ
- **ä»»åŠ¡7.1**: ä½ çš„10åˆ†é’Ÿæ¼”ç¤ºå®Œæ•´æ’ç»ƒ
- **ä»»åŠ¡7.2**: ä¸é˜Ÿå‹20åˆ†é’Ÿæ•´ä½“æ¼”ç¤ºåè°ƒ
- **ä»»åŠ¡7.3**: æŠ€æœ¯é—®ç­”å‡†å¤‡
- **ä»»åŠ¡7.4**: æ¼”ç¤ºç¯å¢ƒæœ€ç»ˆæµ‹è¯•

## 5. WandBç›‘æ§ä¸å¯è§†åŒ–

### 5.1 ç›‘æ§ç­–ç•¥ (åŸºäºå®˜æ–¹æ–‡æ¡£éªŒè¯çš„WandBé›†æˆæ–¹å¼)

#### 5.1.1 ç»§ç»­å­¦ä¹ ç›‘æ§é›†æˆï¼ˆå®˜æ–¹æ–‡æ¡£éªŒè¯ï¼‰
```python
# âœ… åŸºäºå®˜æ–¹æ–‡æ¡£éªŒè¯çš„NeMo-Run + WandBé›†æˆæ–¹å¼
import nemo_run as run
from nemo.collections import llm
from nemo import lightning as nl
from lightning.pytorch.loggers import WandbLogger  # å®˜æ–¹éªŒè¯çš„æ­£ç¡®å¯¼å…¥

# é…ç½®WandB loggeråˆ°recipeä¸­ï¼ˆå®˜æ–¹éªŒè¯æ–¹å¼ï¼‰
def setup_continual_training_with_wandb():
    recipe = llm.qwen25_500m.pretrain_recipe(  # å®˜æ–¹æ–‡æ¡£recipeåˆ—è¡¨éªŒè¯çš„æ­£ç¡®å‘½å
        dir="./models/checkpoints/qwen25_continual",
        name="japanese_continual_learning",
        num_nodes=1,
        num_gpus_per_node=1,
    )
    
    # å®˜æ–¹éªŒè¯çš„WandBé›†æˆåˆ°NeMo trainerä¸­
    wandb_logger = WandbLogger(
        project="qwen25-japanese-continual",
        name="continual-learning-phase",
        entity="your-team",
        tags=["continual-learning", "japanese-wiki", "qwen2.5-0.5b"],
        config={
            "model_size": "0.5B",
            "dataset": "japanese-wikipedia",
            "task": "continual-pretraining"
        }
    )
    
    # å®˜æ–¹æ–‡æ¡£éªŒè¯ï¼šå°†loggeræ·»åŠ åˆ°traineré…ç½®ä¸­
    recipe.trainer.logger = wandb_logger
    recipe.trainer.log_every_n_steps = 10
    
    return recipe

if __name__ == "__main__":
    recipe = setup_continual_training_with_wandb()
    run.run(recipe, executor=run.LocalExecutor())
```

#### 5.1.2 PEFTç›‘æ§é›†æˆï¼ˆå®˜æ–¹æ–‡æ¡£éªŒè¯ï¼‰
```python
# âœ… åŸºäºå®˜æ–¹æ–‡æ¡£éªŒè¯çš„NeMo-Run + WandBé›†æˆåˆ°PEFTè®­ç»ƒ
def setup_peft_training_with_wandb():
    recipe = llm.qwen25_500m.finetune_recipe(  # å®˜æ–¹æ–‡æ¡£recipeåˆ—è¡¨éªŒè¯çš„æ­£ç¡®å‘½å
        dir="./models/checkpoints/qwen25_peft",
        name="japanese_lora",
    num_nodes=1,
    num_gpus_per_node=1,
    peft_scheme="lora",
)
    
    # PEFTä¸“é—¨çš„WandBé…ç½®ï¼ˆå®˜æ–¹éªŒè¯ï¼‰
    wandb_logger = WandbLogger(
        project="qwen25-japanese-peft",
        name="lora-finetuning-phase", 
        entity="your-team",
        tags=["peft", "lora", "japanese-tuning"],
        config={
            "lora_rank": 16,  # é»˜è®¤recipeé…ç½®
            "lora_alpha": 32,
            "base_model": "qwen2.5-0.5b-continued",
            "peft_scheme": "lora"
        }
    )
    
    # å®˜æ–¹éªŒè¯ï¼šé›†æˆloggeråˆ°PEFT trainer
    recipe.trainer.logger = wandb_logger
    recipe.trainer.log_every_n_steps = 5  # PEFTè®­ç»ƒæ­¥æ•°è¾ƒå°‘ï¼Œæ›´é¢‘ç¹è®°å½•
    
    # å®˜æ–¹è¦æ±‚çš„PEFTç‰¹æ®Šé…ç½®
    recipe.trainer.strategy.ckpt_async_save = False
    recipe.trainer.strategy.context_parallel_size = 1
    recipe.trainer.strategy.ddp = "megatron"
    
    return recipe

if __name__ == "__main__":
    recipe = setup_peft_training_with_wandb()
    run.run(recipe, executor=run.LocalExecutor())
```

#### 5.1.3 å›¢é˜Ÿåä½œç›‘æ§ï¼ˆå®˜æ–¹éªŒè¯é…ç½®ï¼‰
```python
# âœ… åŸºäºå®˜æ–¹éªŒè¯çš„å…±äº«WandB workspaceé…ç½®
WANDB_CONFIG = {
    "entity": "your-team",  # å›¢é˜Ÿworkspace
    "projects": {
        "continual": "qwen25-japanese-continual",
        "peft": "qwen25-japanese-peft", 
        "sft": "qwen25-japanese-sft",     # é˜Ÿå‹SFTé¡¹ç›®
        "dpo": "qwen25-japanese-dpo",     # é˜Ÿå‹DPOé¡¹ç›®
        "demo": "qwen25-demo-live"        # æ¼”ç¤ºç›‘æ§
    },
    "tags": ["nemo2.0", "qwen2.5-0.5b", "japanese", "workshop"]
}
```

### 5.2 å¯è§†åŒ–é¢æ¿
- **è®­ç»ƒç›‘æ§**: å®æ—¶æŸå¤±æ›²çº¿ã€å­¦ä¹ ç‡å˜åŒ–ã€GPUåˆ©ç”¨ç‡
- **æ¨¡å‹å¯¹æ¯”**: ä¸‰é˜¶æ®µæ¨¡å‹æ•ˆæœå¯¹æ¯”ï¼ˆåŸå§‹/ç»§ç»­å­¦ä¹ /LoRAå¾®è°ƒï¼‰
- **æ€§èƒ½åˆ†æ**: æ¨ç†é€Ÿåº¦ã€å†…å­˜ä½¿ç”¨ã€æ—¥è¯­ç”Ÿæˆè´¨é‡
- **å›¢é˜Ÿåä½œ**: å…±äº«è¿›åº¦dashboardå’Œå®éªŒç»“æœ

### 5.3 æ¼”ç¤ºæ¨ç†é›†æˆ (åŸºäºå®˜æ–¹æ–‡æ¡£éªŒè¯çš„æ­£ç¡®æ–¹å¼)
```python
# âœ… åŸºäºå®˜æ–¹æ–‡æ¡£éªŒè¯çš„æ¼”ç¤ºæ¨ç†
import torch
from megatron.core.inference.common_inference_params import CommonInferenceParams
import nemo.lightning as nl
from nemo.collections.llm import api
import wandb
import time

def setup_demo_inference():
    # æ¼”ç¤ºç›‘æ§åˆå§‹åŒ–ï¼ˆå®˜æ–¹éªŒè¯ï¼‰
    wandb.init(
        project="qwen25-demo-live",
        name="demo-session",
        entity="your-team",
        tags=["demo", "inference", "qwen2.5-0.5b", "lora"],
        config={
            "model": "qwen2.5-0.5b-lora",
            "checkpoint": "./models/checkpoints/qwen25_peft",
            "inference_params": {
                "temperature": 0.1,
                "top_k": 1,
                "num_tokens_to_generate": 512
            }
        }
    )
    
    # å®˜æ–¹éªŒè¯çš„NeMo inferenceé…ç½®
    strategy = nl.MegatronStrategy(
        tensor_model_parallel_size=1,
        pipeline_model_parallel_size=1,
        context_parallel_size=1,
        sequence_parallel=False,
        setup_optimizers=False,
    )
    
    trainer = nl.Trainer(
        accelerator="gpu",
        devices=1,
        num_nodes=1,
        strategy=strategy,
        plugins=nl.MegatronMixedPrecision(
            precision="bf16-mixed",
            params_dtype=torch.bfloat16,
            pipeline_dtype=torch.bfloat16,
        ),
    )
    
    return trainer

def demo_generate_with_monitoring(trainer, checkpoint_path, prompts):
    """åŸºäºå®˜æ–¹æ–‡æ¡£éªŒè¯çš„æ¨ç†æ¼”ç¤º"""
    
    # æ¨ç†å‚æ•°é…ç½®ï¼ˆå®˜æ–¹éªŒè¯ï¼‰
    inference_params = CommonInferenceParams(
        temperature=0.1, 
        top_k=1, 
        num_tokens_to_generate=512
    )
    
    demo_results = []
    
    for prompt in prompts:
        start_time = time.time()
        
        # ä½¿ç”¨å®˜æ–¹éªŒè¯çš„NeMo APIæ¨ç†
        results = api.generate(
            path=checkpoint_path,
            prompts=[prompt],
            trainer=trainer,
            inference_params=inference_params,
            text_only=True,
        )
        
        inference_time = time.time() - start_time
        response = results[0] if results else "ç”Ÿæˆå¤±è´¥"
        
        # WandBå®æ—¶è®°å½•ï¼ˆå®˜æ–¹éªŒè¯æ–¹å¼ï¼‰
        wandb.log({
            "demo_prompt": prompt,
            "demo_response": response,
            "inference_time": inference_time,
            "response_length": len(response),
            "timestamp": time.time()
        })
        
        demo_results.append({
            "prompt": prompt,
            "response": response,
            "time": inference_time
        })
        
        print(f"Q: {prompt}")
        print(f"A: {response}")
        print(f"Time: {inference_time:.2f}s\n")
    
    return demo_results

# æ¼”ç¤ºè„šæœ¬ä¸»ä½“ï¼ˆå®˜æ–¹è¦æ±‚çš„ç»“æ„ï¼‰
if __name__ == "__main__":
    # æ¼”ç¤ºç”¨prompts
    demo_prompts = [
        "æ—¥æœ¬ã®ç¾ã—ã„å­£ç¯€ã«ã¤ã„ã¦æ•™ãˆã¦ãã ã•ã„ã€‚",
        "äººå·¥çŸ¥èƒ½ã®æœªæ¥ã¯ã©ã†ãªã‚‹ã¨æ€ã„ã¾ã™ã‹ï¼Ÿ", 
        "ç¾å‘³ã—ã„æ–™ç†ã®ãƒ¬ã‚·ãƒ”ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚"
    ]
    
    # PEFTæ¨¡å‹checkpointè·¯å¾„ï¼ˆå®˜æ–¹éªŒè¯æ ¼å¼ï¼‰
    adapter_checkpoint = './models/checkpoints/qwen25_peft/japanese_lora/checkpoints/model_name=0--val_loss=x.xx-step=xxx-consumed_samples=xxx.0-last'
    
    # è®¾ç½®æ¨ç†ç¯å¢ƒï¼ˆå®˜æ–¹éªŒè¯ï¼‰
    trainer = setup_demo_inference()
    
    # æ‰§è¡Œæ¼”ç¤ºæ¨ç†
    results = demo_generate_with_monitoring(trainer, adapter_checkpoint, demo_prompts)
    
    wandb.finish()
```

## 6. ç°æœ‰ä»£ç åˆ©ç”¨

### 6.1 å‚è€ƒä»£ç 
- `sample/abeja-qwen-peft-tuning-example.py`: Qwen2.5-7B LoRAå®ç°
- `sample/abeja-qwen-peft-inference.py`: æ¨ç†è„šæœ¬
- `sample/elyza-peft-tuning-example.py`: ELYZA-Llama2-7Bå®ç°

### 6.2 ä¿®æ”¹è¦ç‚¹
- å°†æ¨¡å‹è§„æ¨¡ä»7Bè°ƒæ•´ä¸º0.5B
- é€‚é…æ—¥è¯­Wikipediaè¯­æ–™åº“
- é›†æˆWandBç›‘æ§åŠŸèƒ½
- å¢åŠ workshopæ¼”ç¤ºåŠŸèƒ½

## 7. æ•´ä½“æ¼”ç¤ºç»“æ„ï¼ˆ20åˆ†é’Ÿæ€»æ—¶é•¿ï¼‰

### 7.1 æ¼”ç¤ºæ—¶é—´åˆ†é…
- **Part 1 - ç»§ç»­å­¦ä¹ +PEFTï¼ˆä½ ï¼‰**: 10åˆ†é’Ÿ
- **Part 2 - SFT+DPOï¼ˆé˜Ÿå‹ï¼‰**: 10åˆ†é’Ÿ
- **æ€»æ—¶é•¿**: 20åˆ†é’Ÿ

### 7.2 Part 1: NeMo 2.0æ–¹æ³•è®ºæ¼”ç¤ºï¼ˆä½ çš„10åˆ†é’Ÿï¼‰

#### 7.2.1 NeMo 2.0æŠ€æœ¯æ ˆå±•ç¤ºï¼ˆ4åˆ†é’Ÿï¼‰
- **Recipeç³»ç»Ÿæ¼”ç¤º**ï¼ˆ2åˆ†é’Ÿï¼‰ï¼š`llm.qwen25_500m.pretrain_recipe()`çš„ä½¿ç”¨æ–¹æ³•
- **NeMo-Runæ‰§è¡Œ**ï¼ˆ1åˆ†é’Ÿï¼‰ï¼š`run.run()`ç»Ÿä¸€æ‰§è¡Œå™¨çš„ä¼˜åŠ¿
- **é…ç½®çµæ´»æ€§**ï¼ˆ1åˆ†é’Ÿï¼‰ï¼š`run.Config`å¯¹è±¡åŒ–é…ç½®çš„ä¾¿åˆ©æ€§

#### 7.2.2 ä¸“ä¸šæ•°æ®å¤„ç†+0.5Bå¿«é€Ÿè¿­ä»£ï¼ˆ4åˆ†é’Ÿï¼‰
- **LLM-JPæ•°æ®å¤„ç†å±•ç¤º**ï¼ˆ1åˆ†é’Ÿï¼‰ï¼šNeMo Curator + Uzushioä¼ä¸šçº§å·¥å…·é“¾
- **è®­ç»ƒé€Ÿåº¦å±•ç¤º**ï¼ˆ2åˆ†é’Ÿï¼‰ï¼š1-2å°æ—¶å®Œæˆç»§ç»­å­¦ä¹ ï¼Œ30åˆ†é’Ÿå®ŒæˆLoRA
- **èµ„æºæ•ˆç‡å¯¹æ¯”**ï¼ˆ1åˆ†é’Ÿï¼‰ï¼š49GBæ˜¾å­˜ä½¿ç”¨<20%ï¼Œé€‚åˆæ•™å­¦ä¸ç ”ç©¶ç¯å¢ƒ

#### 7.2.3 Workshopæ•™å­¦ä»·å€¼ä¸å›¢é˜Ÿåä½œï¼ˆ2åˆ†é’Ÿï¼‰
- **æ•™å­¦å‹å¥½æ€§**ï¼ˆ1åˆ†é’Ÿï¼‰ï¼š0.5Bæ¨¡å‹é€‚åˆå®è·µæ•™å­¦çš„åŸå› 
- **æ ‡å‡†åŒ–äº¤ä»˜**ï¼ˆ1åˆ†é’Ÿï¼‰ï¼šä¸SFT/DPOå›¢é˜Ÿçš„æ— ç¼è¡”æ¥

### 7.3 Part 2: SFT+DPOä¸“é¡¹æ¼”ç¤ºï¼ˆé˜Ÿå‹çš„10åˆ†é’Ÿï¼‰
- **SFTå®ç°**ï¼ˆ4-5åˆ†é’Ÿï¼‰ï¼šç›‘ç£å¾®è°ƒè¿‡ç¨‹å’Œæ•ˆæœ
- **DPOå®ç°**ï¼ˆ4-5åˆ†é’Ÿï¼‰ï¼šåå¥½ä¼˜åŒ–å’Œæœ€ç»ˆæ•ˆæœ
- **æ•´ä½“æ€»ç»“**ï¼ˆ1-2åˆ†é’Ÿï¼‰ï¼šé¡¹ç›®æˆæœå’ŒæŠ€æœ¯ä»·å€¼

### 7.4 æ¼”ç¤ºåè°ƒè¦ç‚¹
- **æŠ€æœ¯è¡”æ¥**ï¼šæ˜ç¡®å±•ç¤ºæ¨¡å‹ä»ä½ åˆ°é˜Ÿå‹çš„ä¼ é€’è¿‡ç¨‹
- **WandBç»Ÿä¸€**ï¼šå…±äº«ç›‘æ§é¢æ¿ï¼Œå±•ç¤ºå®Œæ•´æµç¨‹
- **æ—¶é—´æ§åˆ¶**ï¼šæ¯éƒ¨åˆ†ä¸¥æ ¼æ§åˆ¶åœ¨10åˆ†é’Ÿå†…
- **å¤‡ç”¨é¢„æ¡ˆ**ï¼šå„è‡ªå‡†å¤‡ç‹¬ç«‹çš„æ¼”ç¤ºç¯å¢ƒ

## 8. å›¢é˜Ÿåä½œæ¥å£è®¾è®¡

### 8.1 æ¨¡å‹äº¤ä»˜æ ‡å‡†
```python
# æ ‡å‡†åŒ–æ¨¡å‹è¾“å‡º
def export_model_for_team(model, stage):
    """
    stage: "continual-learned" | "lora-finetuned"
    """
    output_path = f"./models/qwen25_0.5b_{stage}/"
    
    # æ ‡å‡†æ ¼å¼å¯¼å‡º
    model.save_pretrained(output_path)
    
    # äº¤ä»˜æ–‡æ¡£
    create_model_card(output_path, stage)
    
    # WandB artifact
    wandb.save(output_path)
```

### 8.2 è¿›åº¦åŒæ­¥æœºåˆ¶
```python
# å›¢é˜Ÿè¿›åº¦å…±äº«
def update_team_progress(phase, status, metrics):
    wandb.log({
        f"team_progress_{phase}": status,
        f"team_metrics_{phase}": metrics,
        "timestamp": datetime.now()
    })
```

### 8.3 åä½œæ¸…å•
**æ¯æ—¥å›¢é˜ŸåŒæ­¥**:
- [ ] è¿›åº¦æ›´æ–°åˆ°å…±äº«WandB
- [ ] æ¨¡å‹çŠ¶æ€åŒæ­¥
- [ ] æŠ€æœ¯é—®é¢˜è®¨è®º
- [ ] ä¸‹ä¸€æ—¥è®¡åˆ’ç¡®è®¤

**æ¼”ç¤ºåè°ƒ**:
- [ ] æ¼”ç¤ºæ—¶é—´åˆ†é…ï¼šä½ 10åˆ†é’Ÿ + é˜Ÿå‹10åˆ†é’Ÿ
- [ ] æŠ€æœ¯è¡”æ¥ç‚¹ç¡®è®¤ï¼šæ¨¡å‹ä¼ é€’å±•ç¤º
- [ ] WandBç»Ÿä¸€é¢æ¿ï¼šå…±äº«ç›‘æ§å±•ç¤º
- [ ] å¤‡ç”¨é¢„æ¡ˆï¼šå„è‡ªç‹¬ç«‹æ¼”ç¤ºç¯å¢ƒ

## 9. å…³é”®é‡Œç¨‹ç¢‘æ£€æŸ¥ç‚¹

### 9.1 Critical Pathï¼ˆåŸºäº0.5Bæ¨¡å‹ä¼˜åŒ–ï¼‰
- **Day 1**: ç¯å¢ƒéªŒè¯+æ¨¡å‹å¯¼å…¥å®Œæˆï¼ˆ8å°æ—¶å†…ï¼‰
- **Day 2**: ç»§ç»­å­¦ä¹ è®­ç»ƒå®Œæˆï¼ˆ1-2å°æ—¶è®­ç»ƒï¼‰
- **Day 3**: LoRAå¾®è°ƒå®Œæˆï¼ˆ30-60åˆ†é’Ÿè®­ç»ƒï¼‰
- **Day 4-7**: æ¼”ç¤ºå†…å®¹å‡†å¤‡å’Œå¤šç»„å®éªŒ
- **Day 10**: æ¨¡å‹äº¤ä»˜ç»™å›¢é˜Ÿï¼ˆç®€åŒ–æ ¼å¼ï¼‰
- **Day 12**: ä½ çš„10åˆ†é’Ÿæ¼”ç¤ºè„šæœ¬å®Œæˆ
- **Day 13**: 20åˆ†é’Ÿæ•´ä½“æ¼”ç¤ºåè°ƒå®Œæˆ

### 9.2 é£é™©é¢„è­¦ä¸åº”å¯¹ï¼ˆ0.5Bæ¨¡å‹ç°å®ç‰ˆï¼‰
- **å¦‚æœDay 1ç¯å¢ƒæœ‰é—®é¢˜** â†’ ç«‹å³ä½¿ç”¨å¤‡ç”¨ç¯å¢ƒï¼Œ0.5Bæ¨¡å‹èµ„æºéœ€æ±‚ä½
- **å¦‚æœè®­ç»ƒä¸æ”¶æ•›** â†’ é™ä½å­¦ä¹ ç‡ï¼Œ0.5Bæ¨¡å‹å®¹æ˜“è°ƒè¯•
- **å¦‚æœæ¼”ç¤ºæ•ˆæœä¸ä½³** â†’ å¼ºè°ƒæ–¹æ³•è®ºï¼Œæ·¡åŒ–ç”Ÿæˆè´¨é‡å¯¹æ¯”

## 10. é£é™©åˆ†æ

### 10.1 æŠ€æœ¯é£é™©
- **å†…å­˜ä¸è¶³**: 49GBæ˜¾å­˜å¯¹0.5Bæ¨¡å‹è¶³å¤Ÿï¼Œä½†éœ€è°ƒæ•´æ‰¹å¤„ç†å¤§å°
- **æ•°æ®é¢„å¤„ç†**: æ—¥è¯­è¯­æ–™åº“é¢„å¤„ç†è€—æ—¶
- **æ¨¡å‹è½¬æ¢**: HuggingFaceåˆ°NeMoæ ¼å¼è½¬æ¢å¯èƒ½å‡ºé”™
- **å›¢é˜Ÿåä½œ**: æ¨¡å‹äº¤ä»˜æ ¼å¼ä¸å…¼å®¹

### 10.2 ç¼“è§£æªæ–½
- ä¼˜åŒ–æ‰¹å¤„ç†å¤§å°å’Œåºåˆ—é•¿åº¦è®¾ç½®
- æå‰å®Œæˆæ•°æ®é¢„å¤„ç†
- å‡†å¤‡å¤šä¸ªå¤‡ç”¨ç¯å¢ƒ
- åˆ¶å®šæ ‡å‡†çš„æ¨¡å‹äº¤ä»˜æ ¼å¼

## 11. æŠ€æœ¯ç»†èŠ‚

### 11.1 LLM-JPæ•°æ®é¢„å¤„ç†ç®¡é“ï¼ˆNeMo Curator + Uzushioï¼‰

#### 11.1.1 ç¯å¢ƒå‡†å¤‡
```bash
# Apache Sparkç¯å¢ƒè®¾ç½®ï¼ˆNeMo Curatorä¾èµ–ï¼‰
export SPARK_HOME=/opt/spark
export PYSPARK_PYTHON=/usr/bin/python3
export PYSPARK_DRIVER_PYTHON=/usr/bin/python3

# Uzushioå·¥å…·å®‰è£…
pip install uzushio
pip install nemo-curator[all]
```

#### 11.1.2 LLM-JPæ•°æ®ä¸‹è½½ä¸é¢„å¤„ç†
```python
# Step 1: ä¸‹è½½LLM-JP Wikipedia v3æ•°æ®
import os
import subprocess
from pathlib import Path

# åˆ›å»ºæ•°æ®ç›®å½•
data_dir = Path("./data/llm_jp_wiki")
data_dir.mkdir(parents=True, exist_ok=True)

# ä»LLM-JP GitLabä¸‹è½½ï¼ˆéœ€è¦è®¿é—®æƒé™ï¼‰
llm_jp_repo = "https://gitlab.llm-jp.nii.ac.jp/datasets/llm-jp-corpus-v3.git"
subprocess.run([
    "git", "clone", "--depth", "1", 
    "--filter=blob:none", "--sparse-checkout",
    llm_jp_repo, str(data_dir)
])

# è®¾ç½®sparse-checkoutåªä¸‹è½½æ—¥è¯­wikiéƒ¨åˆ†
subprocess.run([
    "git", "-C", str(data_dir), 
    "sparse-checkout", "set", "ja/ja_wiki"
])

# Step 2: ä½¿ç”¨Uzushioè¿›è¡Œåˆæ­¥é¢„å¤„ç†ï¼ˆé€‚åˆ0.5Bæ¨¡å‹çš„æ•°æ®é‡ï¼‰
from uzushio.main import main as uzushio_main

uzushio_config = {
    "input_dir": str(data_dir / "ja/ja_wiki"),
    "output_dir": str(data_dir / "processed"),
    "max_docs": 100000,  # é™åˆ¶æ–‡æ¡£æ•°é‡ï¼Œé€‚åˆ0.5Bæ¨¡å‹
    "min_text_length": 100,
    "max_text_length": 4096,
    "language": "ja",
    "num_workers": 4
}

# æ‰§è¡ŒUzushioé¢„å¤„ç†
uzushio_main(**uzushio_config)

# Step 3: NeMo Curatorè½¬æ¢ä¸ºNeMoæ ¼å¼
from nemo_curator.main import main as curator_main
from nemo_curator.datasets import DocumentDataset
from nemo_curator.modules import ExactDuplicates, FuzzyDuplicates
from nemo_curator.filters import WordCountFilter, LanguageIdentificationFilter

# é…ç½®NeMo Curatorå¤„ç†
curator_config = {
    "input_data_dir": str(data_dir / "processed"),
    "output_data_dir": str(data_dir / "nemo_format"),
    "input_file_type": "jsonl",
    "output_file_type": "parquet",
    
    # é’ˆå¯¹æ—¥è¯­çš„è¿‡æ»¤å™¨
    "filters": [
        WordCountFilter(min_words=10, max_words=2048),
        LanguageIdentificationFilter(language="ja", threshold=0.8)
    ],
    
    # å»é‡å¤„ç†
    "dedup_modules": [
        ExactDuplicates(),
        FuzzyDuplicates(jaccard_threshold=0.8)
    ],
    
    # åˆ†å¸ƒå¼å¤„ç†é…ç½®
    "num_workers": 2,  # é€‚åˆå•æœºç¯å¢ƒ
    "batch_size": 1000
}

# æ‰§è¡ŒNeMo Curatorå¤„ç†
dataset = DocumentDataset.read_json(
    curator_config["input_data_dir"], 
    backend="cudf"  # GPUåŠ é€Ÿ
)

# åº”ç”¨è¿‡æ»¤å™¨å’Œå»é‡
for filter_module in curator_config["filters"]:
    dataset = filter_module(dataset)

for dedup_module in curator_config["dedup_modules"]:
    dataset = dedup_module(dataset)

# ä¿å­˜å¤„ç†åçš„æ•°æ®
dataset.to_parquet(curator_config["output_data_dir"])

# Step 4: è½¬æ¢ä¸ºNeMoè®­ç»ƒæ ¼å¼
from nemo.collections.nlp.data.language_modeling.preprocess_data_for_megatron import main as preprocess_main

# é…ç½®NeMoé¢„å¤„ç†å‚æ•°
nemo_preprocess_config = {
    "input": str(data_dir / "nemo_format"),
    "output_prefix": str(data_dir / "nemo_binary" / "ja_wiki"),
    "vocab_file": "path/to/qwen25_tokenizer/vocab.json",  # Qwen2.5 tokenizer
    "dataset_impl": "mmap",
    "tokenizer_type": "HuggingFaceTokenizer",
    "seq_length": 2048,
    "workers": 4,
    "split_sentences": True,
    "keep_newlines": True
}

# æ‰§è¡Œé¢„å¤„ç†ï¼Œç”Ÿæˆ .bin å’Œ .idx æ–‡ä»¶
preprocess_main(**nemo_preprocess_config)

print("æ•°æ®é¢„å¤„ç†å®Œæˆï¼")
print(f"è®­ç»ƒæ•°æ®: {data_dir}/nemo_binary/ja_wiki_train_text_document.bin/.idx")
print(f"éªŒè¯æ•°æ®: {data_dir}/nemo_binary/ja_wiki_validation_text_document.bin/.idx")
```

#### 11.1.3 é¢„å¤„ç†æ—¶é—´ä¼°ç®—ï¼ˆåŸºäº0.5Bæ¨¡å‹éœ€æ±‚ï¼‰
- **æ•°æ®ä¸‹è½½**: 30-60åˆ†é’Ÿï¼ˆå–å†³äºç½‘ç»œï¼‰
- **Uzushioé¢„å¤„ç†**: 1-2å°æ—¶ï¼ˆ100Kæ–‡æ¡£ï¼Œé€‚åˆ0.5Bæ¨¡å‹ï¼‰
- **NeMo Curatorå¤„ç†**: 2-3å°æ—¶ï¼ˆGPUåŠ é€Ÿå»é‡å’Œè¿‡æ»¤ï¼‰
- **NeMoæ ¼å¼è½¬æ¢**: 1å°æ—¶ï¼ˆç”Ÿæˆ.bin/.idxæ–‡ä»¶ï¼‰
- **æ€»è®¡**: 5-7å°æ—¶ï¼ˆå¯åœ¨Day 1å¹¶è¡Œè¿›è¡Œï¼‰

#### 11.1.4 0.5Bæ¨¡å‹æ•°æ®ä¼˜åŒ–ç­–ç•¥
```python
# é’ˆå¯¹0.5Bæ¨¡å‹çš„æ•°æ®é‡æ§åˆ¶
DATA_OPTIMIZATION = {
    "max_documents": 100000,        # é™åˆ¶æ–‡æ¡£æ•°é‡
    "target_data_size": "1-5GB",    # å¤„ç†åæ•°æ®ç›®æ ‡å¤§å°
    "sequence_length": 2048,        # é€‚ä¸­åºåˆ—é•¿åº¦
    "train_split": 0.95,           # 95%è®­ç»ƒï¼Œ5%éªŒè¯
    "quality_threshold": 0.8,       # è¯­è¨€è¯†åˆ«é˜ˆå€¼
    "dedup_threshold": 0.8          # å»é‡ç›¸ä¼¼åº¦é˜ˆå€¼
}
```

### 11.2 è®­ç»ƒé…ç½® (åŸºäºå®˜æ–¹æ–‡æ¡£éªŒè¯çš„æ­£ç¡®æ–¹å¼)
```python
# âœ… åŸºäºå®˜æ–¹æ–‡æ¡£éªŒè¯çš„NeMo-Runé…ç½®æ–¹å¼
import nemo_run as run
from nemo.collections import llm
from nemo import lightning as nl
from lightning.pytorch.loggers import WandbLogger

# ç»§ç»­å­¦ä¹ é…ç½®ï¼ˆåŸºäºå®˜æ–¹recipeç³»ç»Ÿï¼‰
def setup_continual_pretraining():
    # ä½¿ç”¨å®˜æ–¹0.5Bé¢„è®­ç»ƒrecipe
    recipe = llm.qwen25_500m.pretrain_recipe(
        dir="./models/checkpoints/qwen25_continual",
        name="japanese_continual_learning",
        num_nodes=1,
        num_gpus_per_node=1,
    )
    
    # é…ç½®æ—¥è¯­æ•°æ®ï¼ˆéœ€è¦è‡ªå®šä¹‰DataModuleï¼‰
    recipe.data = run.Config(
        llm.PreTrainingDataModule,
        paths=["/path/to/japanese_wiki_data"],
        seq_length=2048,
        micro_batch_size=1,
        global_batch_size=8,
    )
    
    # WandBé›†æˆ
    wandb_logger = WandbLogger(
        project="qwen25-japanese-continual",
        entity="your-team",
        name="continual-learning"
    )
    recipe.trainer.logger = wandb_logger
    recipe.trainer.max_steps = 1000
    recipe.trainer.log_every_n_steps = 10
    
    return recipe

# PEFT-LoRAé…ç½®ï¼ˆå®Œå…¨åŸºäºsampleä»£ç ï¼‰
def setup_peft_training():
    # ä½¿ç”¨å®˜æ–¹0.5Bå¾®è°ƒrecipeï¼ˆå‚è€ƒsample/abeja-qwen-peft-tuning-example.pyï¼‰
    recipe = llm.qwen25_500m.finetune_recipe(
        dir="./models/checkpoints/qwen25_peft",
        name="japanese_lora",
        num_nodes=1,
        num_gpus_per_node=1,
        peft_scheme="lora",  # å¯ç”¨LoRA
    )
    
    # æ¢å¤ç»§ç»­å­¦ä¹ çš„checkpoint
    recipe.resume.restore_config = run.Config(
        nl.RestoreConfig,
        path='./models/checkpoints/qwen25_continual'
    )
    
    # é…ç½®è‡ªå®šä¹‰æ—¥è¯­å¾®è°ƒæ•°æ®ï¼ˆåŸºäºLLM-JPæ•°æ®çš„LoRAå¾®è°ƒå­é›†ï¼‰
    recipe.data = run.Config(
        JapaneseFineTuningDataModule,  # åŸºäºsampleä»£ç çš„è‡ªå®šä¹‰DataModule
        dataset_root='./data/llm_jp_wiki/finetune_subset/',
        data_prefix='./data/llm_jp_wiki/nemo_binary/ja_wiki_validation_text_document',  # ä½¿ç”¨éªŒè¯é›†ä½œä¸ºå¾®è°ƒæ•°æ®
        seq_length=2048,                # é€‚ä¸­é•¿åº¦ï¼Œ0.5Bæ¨¡å‹ä¸éœ€è¦4096
        micro_batch_size=4,             # 0.5Bæ¨¡å‹å¯ä»¥å¢åŠ 
        global_batch_size=64,           # åˆ©ç”¨49GBæ˜¾å­˜
        num_workers=4,
        pin_memory=True
    )
    
    # PEFTå…³é”®é…ç½®ï¼ˆåŸºäºsampleä»£ç ï¼‰
    recipe.trainer.max_steps = 500
    recipe.trainer.num_sanity_val_steps = 0
    recipe.trainer.strategy.ckpt_async_save = False  # PEFTå¿…éœ€
    recipe.trainer.strategy.context_parallel_size = 1  # å¿…éœ€è®¾ç½®ä¸º1
    recipe.trainer.strategy.ddp = "megatron"  # LoRAå¿…éœ€
    recipe.trainer.val_check_interval = 10
    
    # WandBé›†æˆ
    wandb_logger = WandbLogger(
        project="qwen25-japanese-peft",
        entity="your-team",
        name="lora-finetuning"
    )
    recipe.trainer.logger = wandb_logger
    
    return recipe

# è‡ªå®šä¹‰æ•°æ®æ¨¡å—ï¼ˆåŸºäºLLM-JPæ•°æ®ï¼‰
class JapaneseFineTuningDataModule(FineTuningDataModule):
    """åŸºäºLLM-JP Wikipediaæ•°æ®çš„å¾®è°ƒæ¨¡å—ï¼Œå‚è€ƒsample/abeja-qwen-peft-tuning-example.py"""
    
    def __init__(self, data_prefix, **kwargs):
        super().__init__(**kwargs)
        self.data_prefix = data_prefix
        self.train_ds = self._create_dataset(f"{data_prefix}_train_text_document")
        self.validation_ds = self._create_dataset(f"{data_prefix}_validation_text_document")
    
    def _create_dataset(self, data_path):
        """åˆ›å»ºåŸºäºLLM-JPäºŒè¿›åˆ¶æ•°æ®çš„æ•°æ®é›†"""
        from nemo.collections.nlp.data.language_modeling.megatron_gpt_dataset import GPTDataset
        
        return GPTDataset(
            data_prefix=data_path,
            documents=None,
            indexed_dataset=None,
            num_samples=None,
            seq_length=self.seq_length,
            seed=1234,
            return_doc_ids=False
        )
    
    def form_instruction_response(self, text_segment):
        """å°†LLM-JPæ–‡æœ¬æ ¼å¼åŒ–ä¸ºæŒ‡ç¤º-å“åº”æ ¼å¼"""
        # ç®€å•çš„æ–‡æœ¬åˆ†å‰²ç­–ç•¥ï¼Œå°†é•¿æ–‡æœ¬åˆ†ä¸ºé—®é¢˜-ç­”æ¡ˆå¯¹
        sentences = text_segment.split('ã€‚')
        if len(sentences) >= 2:
            question = sentences[0] + 'ã€‚'
            response = 'ã€‚'.join(sentences[1:3]) + 'ã€‚'
            
            formatted = f"### æŒ‡ç¤º:\nä»¥ä¸‹ã®å†…å®¹ã«ã¤ã„ã¦èª¬æ˜ã—ã¦ãã ã•ã„ã€‚\n"
            formatted += f"### å…¥åŠ›:\n{question}\n"
            formatted += f"### å¿œç­”:\n{response}"
            return formatted
        else:
            return text_segment

# æ¨èé…ç½®å‚æ•°ï¼ˆ0.5Bæ¨¡å‹ä¼˜åŒ–ï¼Œèµ„æºé«˜æ•ˆï¼‰
CONTINUAL_LEARNING_CONFIG = {
    "micro_batch_size": 4,     # å¯ä»¥å¢åŠ ï¼Œ0.5Bæ¨¡å‹æ˜¾å­˜éœ€æ±‚ä½
    "global_batch_size": 64,   # åˆ©ç”¨49GBæ˜¾å­˜ä¼˜åŠ¿
    "sequence_length": 2048,   # é€‚ä¸­é•¿åº¦ï¼Œå¤Ÿç”¨
    "max_steps": 500,          # 0.5Bæ¨¡å‹æ”¶æ•›å¿«ï¼Œå‡å°‘steps
    "log_every_n_steps": 5     # æ›´é¢‘ç¹è®°å½•ï¼Œä¾¿äºç›‘æ§
}

PEFT_CONFIG = {
    "peft_scheme": "lora",
    "micro_batch_size": 4,     # åˆ©ç”¨æ˜¾å­˜å……è¶³ä¼˜åŠ¿
    "global_batch_size": 64,   # å¢åŠ batch size
    "sequence_length": 2048,   # ä¸éœ€è¦4096ï¼Œ2048å¤Ÿç”¨
    "max_steps": 200,          # 0.5Bæ¨¡å‹PEFTæ”¶æ•›å¾ˆå¿«
    "val_check_interval": 5,   # æ›´é¢‘ç¹éªŒè¯
    # å…³é”®PEFTé…ç½®ï¼ˆå®˜æ–¹è¦æ±‚ï¼‰
    "ckpt_async_save": False,
    "context_parallel_size": 1,
    "ddp": "megatron"
}

# æ‰§è¡Œæ–¹å¼ï¼ˆå¿…é¡»ä½¿ç”¨ï¼‰
if __name__ == "__main__":
    # ç»§ç»­å­¦ä¹ 
    continual_recipe = setup_continual_pretraining()
    run.run(continual_recipe, executor=run.LocalExecutor())
    
    # PEFTå¾®è°ƒ
    peft_recipe = setup_peft_training()
    run.run(peft_recipe, executor=run.LocalExecutor())
```

### 11.3 è¯„ä¼°æŒ‡æ ‡
- æ—¥è¯­ç”Ÿæˆè´¨é‡
- æ¨ç†é€Ÿåº¦
- å†…å­˜ä½¿ç”¨æƒ…å†µ
- å­¦ä¹ æ•ˆç‡
- **WandBç›‘æ§æŒ‡æ ‡**: å®æ—¶lossã€perplexityã€GPUåˆ©ç”¨ç‡

## 12. é¢å¤–è€ƒè™‘

### 12.1 è®¸å¯è¯
- Qwen2.5: Apache 2.0
- Wikipedia: CC BY-SA
- NeMo: Apache 2.0
- WandB: å…è´¹å­¦æœ¯ä½¿ç”¨

### 12.2 è®­ç»ƒæ•°æ®ï¼ˆåŸºäºLLM-JPä¸“ä¸šè¯­æ–™åº“ï¼‰
- **LLM-JP Wikipedia v3**: 1-5GBï¼ˆNeMo Curatorå¤„ç†åï¼‰
  - æ¥æºï¼šå›½ç«‹æƒ…æŠ¥å­¦ç ”ç©¶æ‰€ï¼ˆNIIï¼‰ä¸“ä¸šæ¸…æ´—æ•°æ®
  - æ ¼å¼ï¼štrain_text_document.bin/.idx, validation_text_document.bin/.idx
  - è´¨é‡ï¼šä¸“ä¸šå»é‡ã€è¿‡æ»¤ã€è¯­è¨€æ£€æµ‹çš„é«˜è´¨é‡æ—¥è¯­è¯­æ–™
- **æ•°æ®åˆ†å‰²**: 95%è®­ç»ƒï¼Œ5%éªŒè¯ï¼ˆé€‚åˆ0.5Bæ¨¡å‹ï¼‰
- **å¤„ç†å·¥å…·**: NeMo Curator + Uzushioï¼ˆä¼ä¸šçº§ä½†é€‚é…0.5Béœ€æ±‚ï¼‰

### 12.3 è®¡ç®—èµ„æºï¼ˆæ¼”ç¤ºå¯¼å‘ï¼‰
- GPUåˆ©ç”¨ç‡: é¢„è®¡70-80%ï¼ˆè®­ç»ƒæ—¶ï¼‰ï¼Œ< 30%ï¼ˆæ¨ç†æ¼”ç¤ºæ—¶ï¼‰
- è®­ç»ƒæ—¶é—´: æŒç»­å­¦ä¹ 6å°æ—¶ï¼ŒLoRAå¾®è°ƒ2å°æ—¶
- æ¼”ç¤ºè¿è¡Œ: æ¨¡å‹åŠ è½½< 30ç§’ï¼Œæ¨ç†å“åº”< 2ç§’
- ç£ç›˜ç©ºé—´: çº¦éœ€100GBï¼ˆå¼€å‘ï¼‰ï¼Œ20GBï¼ˆæ¼”ç¤ºç¯å¢ƒï¼‰
- **æ¼”ç¤ºæ—¶é—´**: ä½ çš„éƒ¨åˆ†10åˆ†é’Ÿï¼Œé˜Ÿå‹10åˆ†é’Ÿï¼Œæ€»å…±20åˆ†é’Ÿ

## 13. æˆåŠŸæŒ‡æ ‡ï¼ˆ0.5Bæ¨¡å‹workshopç‰ˆï¼‰

### 13.1 æŠ€æœ¯æ–¹æ³•è®ºæŒ‡æ ‡ï¼ˆä¸»è¦ï¼‰
- âœ… NeMo 2.0 recipeç³»ç»ŸæˆåŠŸè¿è¡Œ
- âœ… ç»§ç»­å­¦ä¹ â†’PEFTå®Œæ•´é“¾è·¯æ‰“é€š  
- âœ… WandBç›‘æ§é›†æˆå·¥ä½œæ­£å¸¸
- âœ… å¿«é€Ÿè¿­ä»£ä¼˜åŠ¿æˆåŠŸå±•ç¤ºï¼ˆè®­ç»ƒæ—¶é—´<3å°æ—¶æ€»è®¡ï¼‰
- âœ… å›¢é˜Ÿæ¨¡å‹äº¤ä»˜æ ¼å¼æ ‡å‡†åŒ–

### 13.2 æ¼”ç¤ºä»·å€¼æŒ‡æ ‡ï¼ˆæ ¸å¿ƒï¼‰
- **ä½ çš„10åˆ†é’Ÿæ¼”ç¤º**ï¼š
  - âœ… NeMo 2.0æ–¹æ³•è®ºæ¸…æ™°å±•ç¤º
  - âœ… 0.5Bæ¨¡å‹æ•™å­¦ä¼˜åŠ¿çªå‡º
  - âœ… æŠ€æœ¯æµç¨‹æ¼”ç¤ºæµç•…æ— æ•…éšœ
  - âœ… æ—¶é—´æ§åˆ¶ç²¾å‡†ï¼ˆ10åˆ†é’ŸÂ±30ç§’ï¼‰
- **æ•´ä½“20åˆ†é’Ÿæ¼”ç¤º**ï¼š
  - âœ… æŠ€æœ¯è¡”æ¥æ¸…æ™°ï¼šç»§ç»­å­¦ä¹ â†’PEFTâ†’SFTâ†’DPO
  - âœ… å›¢é˜Ÿåä½œå±•ç¤ºï¼šç»Ÿä¸€WandBç›‘æ§
  - âœ… Workshopæ•™å­¦ä»·å€¼çªå‡º

### 13.3 ç°å®æœŸæœ›ç®¡ç†ï¼ˆé‡è¦ï¼‰
- âŒ **ä¸è¿½æ±‚**ï¼šä¸å¤§æ¨¡å‹ç›¸å½“çš„ç”Ÿæˆè´¨é‡
- âŒ **ä¸å¼ºè°ƒ**ï¼šå¤æ‚çš„æ€§èƒ½ä¼˜åŒ–
- âŒ **ä¸è¿‡åº¦**ï¼šä¼ä¸šçº§éƒ¨ç½²å¤æ‚åº¦
- âœ… **çªå‡ºä»·å€¼**ï¼šæ–¹æ³•è®ºæ•™å­¦+å¿«é€Ÿè¿­ä»£+èµ„æºæ•ˆç‡

## 14. NeMo 2.0æ‰§è¡Œæ£€æŸ¥æ¸…å• (åŸºäºå®˜æ–¹æ–‡æ¡£éªŒè¯çš„æ­£ç¡®æ–¹å¼)

### âœ… 14.1 å¼€å‘å‰å¿…æ£€é¡¹ç›®
- [ ] **ç¡®è®¤å®¹å™¨ç‰ˆæœ¬**: ä½¿ç”¨NeMo 25.04æˆ–æ›´æ–°ç‰ˆæœ¬
- [ ] **å®‰è£…nemo-run**: `pip install nemo-run`ï¼ˆå¿…éœ€ï¼‰
- [ ] **éªŒè¯å¯¼å…¥**: `import nemo_run as run` å’Œ `from nemo.collections import llm` æˆåŠŸ
- [ ] **WandBå›¢é˜Ÿé…ç½®**: ç¡®è®¤entityå’Œprojectæƒé™
- [ ] **æ¨¡å‹è®¿é—®æƒé™**: ç¡®è®¤Qwen2.5-0.5Bçš„HuggingFaceè®¿é—®æƒé™
- [ ] **æœ¬åœ°å­˜å‚¨**: é¢„ç•™5-10GBç©ºé—´ç”¨äºæ¨¡å‹å’Œcheckpoint

### 14.2 æ¯æ—¥å¼€å‘æ£€æŸ¥ (åŸºäºå®˜æ–¹æ–‡æ¡£éªŒè¯æ¨¡å¼)
- [ ] **ä»£ç ç»“æ„**: å¿…é¡»ä½¿ç”¨`if __name__ == "__main__":`åŒ…è£…ï¼ˆå®˜æ–¹è¦æ±‚ï¼‰
- [ ] **é…ç½®æ–¹å¼**: ä½¿ç”¨`run.Config`å’Œrecipeç³»ç»Ÿï¼ˆå®˜æ–¹æ–¹å¼ï¼‰
- [ ] **æ‰§è¡Œæ–¹å¼**: é€šè¿‡`run.run(recipe, executor=run.LocalExecutor())`ï¼ˆå®˜æ–¹æ ‡å‡†ï¼‰
- [ ] **WandBé›†æˆ**: é€šè¿‡`lightning.pytorch.loggers.WandbLogger`é›†æˆåˆ°trainerä¸­ï¼ˆå®˜æ–¹éªŒè¯ï¼‰
- [ ] **æ¨¡å‹å¯¼å…¥**: ä½¿ç”¨`llm.import_ckpt()`ä¸€æ¬¡æ€§å¯¼å…¥æœ¬åœ°ï¼ˆå®˜æ–¹æ–¹å¼ï¼‰

### 14.3 è®­ç»ƒæµç¨‹éªŒè¯ (æŒ‰å®˜æ–¹æ–‡æ¡£æ ‡å‡†)
- [ ] **æ¨¡å‹å¯¼å…¥**: `llm.import_ckpt()` æˆåŠŸå¯¼å…¥0.5Bæ¨¡å‹
- [ ] **ç»§ç»­å­¦ä¹ **: `llm.qwen25_500m.pretrain_recipe()` æ­£å¸¸è¿è¡Œï¼ˆå®˜æ–¹æ–‡æ¡£recipeåˆ—è¡¨éªŒè¯å‘½åï¼‰
- [ ] **PEFTé…ç½®**: `peft_scheme="lora"` + å®˜æ–¹è¦æ±‚çš„ç‰¹æ®Šé…ç½®åº”ç”¨
- [ ] **checkpointä¿å­˜**: è®­ç»ƒè¿‡ç¨‹æ­£å¸¸ä¿å­˜checkpoint
- [ ] **æ¨ç†æµ‹è¯•**: `api.generate()` èƒ½å¤Ÿæ­£å¸¸æ¨ç†

### 14.4 å…³é”®é…ç½®éªŒè¯ (å®˜æ–¹æ–‡æ¡£è¦æ±‚)
- [ ] **PEFTç‰¹æ®Šé…ç½®**ï¼ˆå®˜æ–¹è¦æ±‚ï¼‰: 
  - `recipe.trainer.strategy.ckpt_async_save = False`
  - `recipe.trainer.strategy.context_parallel_size = 1`
  - `recipe.trainer.strategy.ddp = "megatron"`
- [ ] **æ•°æ®é…ç½®**: `run.Config(DataModule, ...)` æ­£ç¡®é…ç½®ï¼ˆå®˜æ–¹æ–¹å¼ï¼‰
- [ ] **WandB Logger**: æ­£ç¡®é›†æˆåˆ°`recipe.trainer.logger`ï¼ˆå®˜æ–¹éªŒè¯ï¼‰
- [ ] **checkpointè·¯å¾„**: è·¯å¾„æ ¼å¼ç¬¦åˆNeMoæ ‡å‡†

### 14.5 æ¼”ç¤ºç¯å¢ƒéªŒè¯
- [ ] **æ¨ç†é…ç½®**: MegatronStrategy + nl.Trainer è®¾ç½®æ­£ç¡®
- [ ] **checkpointè·¯å¾„**: PEFTæ¨¡å‹checkpointå­˜åœ¨ä¸”å¯è®¿é—®
- [ ] **æ¨ç†å‚æ•°**: CommonInferenceParams é…ç½®åˆç†
- [ ] **WandBæ¼”ç¤º**: å®æ—¶ç›‘æ§æ­£å¸¸å·¥ä½œ
- [ ] **æ—¥è¯­æµ‹è¯•**: æ—¥è¯­è¾“å…¥è¾“å‡ºæ­£å¸¸æ˜¾ç¤º

### 14.6 é¿å…çš„å¸¸è§é”™è¯¯ (åŸºäºå®˜æ–¹æ–‡æ¡£åˆ†æ)
- âŒ **ä¸ä½¿ç”¨recipeç³»ç»Ÿ**: å¿…é¡»ä½¿ç”¨`llm.qwen25_500m.finetune_recipe()`ï¼ˆå®˜æ–¹æ–‡æ¡£recipeåˆ—è¡¨éªŒè¯ï¼‰
- âŒ **å¿˜è®°if __name__**: è¿™æ˜¯å®˜æ–¹è¦æ±‚çš„å¿…éœ€ç»“æ„
- âŒ **ç›´æ¥è¿è¡Œ.py**: å¿…é¡»é€šè¿‡`run.run()`æ‰§è¡Œï¼ˆå®˜æ–¹æ ‡å‡†ï¼‰
- âŒ **é”™è¯¯çš„checkpointè·¯å¾„**: å¿…é¡»ä½¿ç”¨å®Œæ•´çš„NeMo checkpointè·¯å¾„
- âŒ **å¿½ç•¥PEFTç‰¹æ®Šé…ç½®**: LoRAè®­ç»ƒå¿…éœ€çš„ç­–ç•¥é…ç½®ï¼ˆå®˜æ–¹è¦æ±‚ï¼‰

## 15. åç»­å‘å±•

### 15.1 æ‰©å±•å¯èƒ½æ€§
- æ”¯æŒæ›´å¤§è§„æ¨¡æ¨¡å‹ï¼ˆ1Bã€3Bï¼‰
- é›†æˆæ›´å¤šæ—¥è¯­ä»»åŠ¡æ•°æ®é›†
- å¼€å‘å›¾å½¢åŒ–ç•Œé¢å·¥å…·
- **WandBæ¨¡æ¿**: å¯å¤ç”¨çš„ç›‘æ§æ¨¡æ¿

### 15.2 ç¤¾åŒºè´¡çŒ®
- å¼€æºå®Œæ•´å®ç°ä»£ç 
- å‘å¸ƒæŠ€æœ¯åšå®¢å’Œæ•™ç¨‹
- å‚ä¸NeMoç¤¾åŒºè®¨è®º
- **WandBæ¡ˆä¾‹**: åˆ†äº«æœ€ä½³å®è·µ

### 15.3 å­¦æœ¯åº”ç”¨
- æ€§èƒ½åŸºå‡†æµ‹è¯•æŠ¥å‘Š
- å¤šè¯­è¨€æ¨¡å‹æ¯”è¾ƒç ”ç©¶
- æ•™è‚²åº”ç”¨æ¡ˆä¾‹åˆ†æ 
- **ç›‘æ§æ–¹æ³•è®º**: WandBåœ¨NLPä¸­çš„åº”ç”¨ç ”ç©¶ 